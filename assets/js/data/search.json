[ { "title": "论文阅读笔记-金融", "url": "/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E9%87%91%E8%9E%8D/", "categories": "Research", "tags": "", "date": "2024-08-14 00:00:00 +0000", "snippet": "美国衰退的判断依据与历史经验陈刚-CICC2024经济衰退（Economic recession）是指经济活动严重、广泛且长期的低迷。美国关于衰退的阶段划分长期以来由国家经济研究局（National Bureau of Economic Research，NBER）认定，主要考察的指标包括扣除转移支付后的个人实际收入、非农就业、家庭调查就业、实际个人消费支出、实际制造与贸易销售、以及工业产出。NBER在认定衰退时，会综合考虑深度（depth）、广度（diffusion）、以及持续时间（duration）。发现触发因素可大体归结为货币紧缩、财政减支、高杠杆、股市大跌、及外部冲击这五种情形的一种或多种。行业表现：日常消费及防御板块在回撤期间跌幅普遍较小，符合防御板块特征；但房地产、金融服务、媒体、公用事业、保险等板块在深度衰退期间跌幅更为剧烈，意味着此类板块对于衰退程度更加敏感，相比之下成长风格的科技板块敏感度相对较低。此外，衰退不同阶段资产表现也有差异：1）初期，原油最好，黄金及国债其次，美元及工业金属一般，新兴与成长股、信用债落后；上中游周期领先，防御/日常消费其中，金融地产、科技及可选消费不佳；2）中期，原油及工业金属回落，债券最好，美股修复；防御/日常消费最好，上中游周期回落，金融地产及科技修复；3）后期，美股、新兴及工业金属修复，债券一般，原油落后，黄金最差；金融地产及可选消费最好，上中游周期及科技媒体修复，防御/日常消费最差。从资产角度，在经济“软着陆”和美联储小幅降息的基本假设下，降息兑现前，分母端（如美债、黄金）资产还是可以做而且弹性更大，分子端风险资产（如美股、铜等）会有压力，这也是每次降息交易的典型“套路降息开启前，受益于宽松的降息交易依然可以参与。受益于降息分母端流动性改善的资产有一定空间且弹性更大，但由于没有其他受益逻辑，需要把握节奏“且战且退”，例如美债、黄金以及缺乏盈利支撑的小盘股；分子端风险资产面临回调压力，但由于不是衰退情形，风险资产不会持续承压，回调也为后续提供了介入机会。降息兑现后，降息同时解决分子和分母问题的资产会更好。降息以后，受益于融资成本下行带来的需求抬升，进而改善分子端盈利的资产，相对配置价值上升。降息兑现时可能也是降息交易的尾声之时，逐步再转向再通胀受益资产，如美股及铜油等大宗资源品。" }, { "title": "金融知识", "url": "/HeBlog/posts/%E9%87%91%E8%9E%8D%E7%9F%A5%E8%AF%86/", "categories": "Finance", "tags": "", "date": "2024-02-19 00:00:00 +0000", "snippet": "MLF、LPR：中期借贷便利（Medium-term Lending Facility，简称MLF）利率或“市场报价利率”。现在贷款市场报价利率（Loan Prime Rate，简称LPR，英文直译为“贷款基准利率”）主要是由中期借贷便利利率（MLF），加点形成。https://finance.sina.com.cn/zl/china/2022-05-20/zl-imcwipik0899962.shtml#:~:text=%E5%A4%AE%E8%A1%8C%E6%94%BF%E7%AD%96%E5%88%A9%E7%8E%87%EF%BC%8C%E6%98%AF,%E5%B7%A5%E5%85%B7%E5%92%8C%E5%88%A9%E7%8E%87%E6%B0%B4%E5%B9%B3%E3%80%82沪金主连、黄金9999、黄金T+D、mAu(T+D)： https://xueqiu.com/2770678756/245099175费雪方程式：货币数量 * 货币流通速度 = 产品价格 * 产品产量 https://mp.weixin.qq.com/s/xk0ebZrf0l4pT-yR839biQ&amp;gt;债券repoTRS债券期货是利率期货(Interest Rate Futures)的一种，是一种标准化的买卖合约，标的为一定数量的某种利率相关的商品，通常是一个中长期债券。" }, { "title": "论文阅读笔记-多模态", "url": "/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E5%A4%9A%E6%A8%A1%E6%80%81/", "categories": "Research", "tags": "", "date": "2024-02-01 00:00:00 +0000", "snippet": "MergeNet: Knowledge Migration across Heterogeneous Models, Tasks, and Modalities项目地址解读文章现有的知识转移方法主要有两种：知识蒸馏和迁移学习。知识蒸馏通过训练一个紧凑的学生模型来模仿教师模型的 Logits 或 Feature Map，提高学生模型的准确性。迁移学习则通常通过预训练和微调，将预训练阶段在大规模数据集上学到的知识通过骨干网络共享应用于下游任务。知识蒸馏、骨干共享和 MergeNet 的比较MergeNet 框架MUST: An Effective and Scalable Framework for Multimodal Search of Target Modality-Yunjun Gao-Zhejiang University将图实体转换为向量，构建图索引，搜索These baselines either merge the results of separate vector searches for each modality or perform a single-channel vector search by fusing all modalities.Our framework employs a hybrid fusion mechanism, combining different modalities at multiple stages. Notably, we leverage vector weight learning to determine the importance of each modality, thereby enhancing the accuracy of joint similarity measurement. Additionally, the proposed framework utilizes a fused proximity graph index, enabling efficient joint search for multimodal queries. MUST offers several other advantageous properties, including pluggable design to integrate any advanced embedding techniques, user flexibility to customize weight preferences, and modularized index construction.我们的框架采用了混合融合机制，在多个阶段结合了不同的模式。值得注意的是，我们利用向量权重学习来确定每个模态的重要性，从而提高了联合相似性度量的准确性。此外，提出的框架利用融合接近图索引，使联合搜索多模态查询成为可能。MUST提供了其他几个有利的特性，包括可插入的设计，以集成任何先进的嵌入技术，用户定制权重偏好的灵活性，以及模块化的索引构造。Connecting Multi-modal Contrastive Representations浙江大学论文地址：https://arxiv.org/abs/2305.14381项目主页：https://c-mcr.github.io/C-MCR/模型和代码地址：https://github.com/MCR-PEFT/C-MCRwechat:「无需配对数据」就能学习！浙大等提出连接多模态对比表征C-MCR｜NeurIPS 2023这些缺乏配对数据的模态组合，往往和同一个中间模态具有大量高质量配对数据。 考虑到具有大量配对数据的模态间往往已经拥有预训练的对比表示，本文直接尝试通过枢纽模态来将不同模态间的对比表征连接起来，从而为缺乏配对数据的模态组合构建新的对比表征空间。On the Essence and Prospect: An Investigation of Alignment Approaches for Big Models https://arxiv.org/abs/2403.04204wechat:大模型的对齐技术综述以及前沿讨论：个性化对齐和多模态对齐大模型在人工智能领域取得了革命性的突破，但它们也可能带来潜在的担忧。为了解决这些担忧，引入了对齐技术，以使这些模型遵循人类的偏好和价值观。尽管过去一年取得了相当大的进展，但在建立最佳对齐策略时仍然存在各种挑战，例如数据成本和可扩展的监督，如何对齐仍然是一个悬而未决的问题。在这篇综述文章中，作者全面调查了价值对齐方法。文章首先解析对齐的历史背景，追溯到20世纪20年代（它来自哪里），然后深入探讨对齐的数学本质（它是什么），揭示了固有的挑战。在此基础上，作者详细检查了现有的对齐方法，这些方法分为三类：强化学习、监督式微调和上下文内学习，并展示了它们之间的内在联系、优势和局限性，帮助读者更好地理解这一研究领域。此外，还讨论了两个新兴主题：个性化对齐和多模态对齐，作为该领域的新前沿。展望未来，文章讨论了潜在的对齐范式以及它们如何处理剩余的挑战，展望了未来对齐的发展方向。LLMs的对齐方法主要分为三种范式：基于强化学习的对齐、基于监督式微调的对齐和上下文内对齐。@article{MRAGSurvey, title={A Survey on Multimodal Retrieval-Augmented Generation}, author={Lang Mei, Siyu Mo, Zhihan Yang, Chong Chen}, year={2025}, organization={GitHub}, url={https://github.com/PanguIR/MRAGSurvey},}" }, { "title": "电脑问题", "url": "/HeBlog/posts/%E7%94%B5%E8%84%91%E9%97%AE%E9%A2%98/", "categories": "Help", "tags": "", "date": "2023-06-05 00:00:00 +0000", "snippet": "电脑问题小工具     破解word加密？ 先转为rar，搜索documentProtection。https://blog.csdn.net/sinat_42483341/article/details/86219258 excel随机数 =INDIRECT(“A”&amp;amp;RANDBETWEEN(1,10)) win     在Windows上修复“0xc0000022” https://www.cnblogs.com/oplusx/p/11818963.html 自动设置Windows聚焦背景为桌面壁纸 http://www.xitonghe.com/jiaocheng/Windows10-9338.html Win10桌面图标显示不正常怎么办？ http://www.xitongzhijia.net/xtjc/20190409/153615.html 便签无网 https://answers.microsoft.com/zh-hans/windows/forum/all/%E5%BE%AE%E8%BD%AF%E8%87%AA%E5%B8%A6%E5%BA%94/c5345e6f-4b70-4bdb-b2ed-e8414c266750 重装或更新网卡驱动时遇到错误代码56的解决办法 清理注册表 https://baijiahao.baidu.com/s?id=1713227398841422660&amp;amp;wfr=spider&amp;amp;for=pc&amp;amp;searchword= github无法提交代码 github有两种登陆模式，通过oAuth或者生成的access码。有两种通信协议ssh和https。oauth可能有些操作没权限，access可以设置权限。当配置好但无法访问github时，因为需要翻墙，需要配置自己的电脑代理，可以通过git config –global http.proxy 127.0.0.1:7890 git config –global https.proxy 127.0.0.1:7890命令设置代理 ipad     ipad快捷键 http://www.pptgeek.com/727/ linux     Linux–由笔记本合盖不休眠探究logind.conf配置 https://blog.csdn.net/dkx523121943/article/details/81545799 " }, { "title": "Njust Cse Course Design", "url": "/HeBlog/posts/NJUST-CSE-course-design/", "categories": "", "tags": "", "date": "2022-09-13 00:00:00 +0000", "snippet": "NJUST-CSE-course-designCourse design of College of Computer Science and Technology, Nanjing University Of Science And Technology南京理工大学 计算机科学与工程学院 课程设计前言课设，不可谓不头疼，不可谓不肝。记得每年小学期做得时候天都是黑暗的，过完了之后就感觉头顶的天都亮了。无数个夜晚和清晨，你见过南京清晨四点半的太阳吗？再睡到12点hh考虑到自己已经做了一遍，希望给学弟学妹留下指引，所以在这个项目会写课设的思路，问题等，也会放一些代码供以参考。但是，有代码并不能直接cv，必须要自己写！！！课设的意义就在于对课程学习的内容的实践，在实践中体会理论，发现问题。去思考自己学的东西，思考这样做的合理性，发现自己感兴趣的方向，从工程的角度考虑项目。我以前并没有体会到这些，学习是为了应付考试，得到成绩，可在毕业的时候，看到身边的同学们找工作时临时抱佛脚的焦虑，自己研究生面试被问的体无完肤，我体会到学习是为了自己。所以，希望大家能核心课程用心学，课设用心做。耗费时间整理这个项目是为了给南理工人带来方便，因为我爱南理工，爱这所学校，也感谢这所学校，希望能用自己的脚印给它留下一些财富。当然自己的学识有限，难免会有疏忽和错误，如果对项目的问题，可以联系我，邮箱alan.lee1998@outlook.com。也可以咨询选课和学习的问题，但拒绝巨婴。汇编：当前日期间隔n天的日期输出根据日期（判断输入个是）加年加月，考虑区分闰年，输出时需要转换为十进制，单位数补0 。C++：英语单词学习软件 单词表读取，需要进行分词，对于存储可使用容器，防止像我一样定义String[3000]的组，整体处理以String处理较方便。较成熟的可以考虑使用数据库。 定义背的次数数组，根据相应的逻辑规则显示词语，设定会，不会等状态。对于经常不会的词语进行判断提高出现频率。 智能推荐功能，对单词相似度进行排序，选择字母相似较多的词语。 输出需要注意排版问题。 注意：没有图形界面的程序，需要判定用户的输入是否合法。对于团队项目，我们做了人机人人五子棋，用的QT，包括声音等特点。JavaEE：酒店管理系统这个项目就用的课上教的Servlet、JSP、JDBC写的，加入了Hibernate管理数据库。bean用来对接数据库，进行事务处理；entity用来定义实体，转换数据库对象。servlet用来处理前端JSP页面的请求，处理页面跳转，调用bean层，处理业务产生的数据。架构很简单，但是实现起来并不简单，功能适中，基本业务需求都有。首先为什么不简单，因为架构简单，这不废话吗？这里说一下复杂在那里，这也是最初Web开发的问题，之后才衍生出了SSH、SSM、Spring、到现在的SpringBoot、SpringCloud。 首先，配置环境及其复杂，当时我已经知道很多组配环境配的焦头烂额，可能大家刚接触Web项目吧。Java、Tomcat、Mysql、JDBC、MyEclipse这些的配置，Tomcat的启动、端口号冲突等问题，mysql和JDBC的版本兼容问题，mysql在windows中很难卸载干净，ME的激活问题以及在mysql中配置tomcat也很复杂。 这些都阻碍着我们的开发，当然直到现在配环境也是个让人头疼的问题。所以对于一个项目有现成的基础框架或者直接不需要佩环境是难得可贵的。一些新技术也应运而生，包括SpringBoot的建议配置，IDEA的全面人性辅助开发，所以推荐大家使用先进但成熟的技术。当然mysql 6和8孰优孰劣有待争议，均可，编译器推荐IDEA等等。 开发代码的复杂，你根本不知道Servlet和JSP传变量有多复杂，不断的重新声明，一个个request，复杂，零乱。同时在页面跳转之后，JSP又要重新得到一样的变量。 前后端不分离，这就带来开发的复杂。我们需要一个人即写前端又写后端，这本来任务量就大。还有项目的同步，我们使用的SVN，这减轻了一些对接的复杂，如果没有就来回拷代码。 配置项目的复杂，对于每个Servlet都需要在项目xml文件中声明。 当然现在有了很多新技术，这个项目会有很多问题，当然做一遍的好处，就是能深刻体会这些问题，再感叹新技术的好。下面介绍以下项目，角色老板、前台、顾客。功能上包括订房和订餐，殊涂同归，加之一些辅助功能，例如查看库存，报表统计等功能。这里说一下开发中的问题。 对于客房的状态，我们使用1234等状态进行标识。 对于订单，需要增加项表，而不是在商品数据库上进行增加列。Linux：线程池这里，一个是在linux中，c++程序和在windows中的编译运行不一样，需要生成.o的中间文件。一个进程、线程以及线程池的区别，进程是隔离的单个程序，线程是共享部分资源的程序，线程池则可以附带对线程的管理，动态分配线程。编译原理：编译器此项目用C++编写了包括词法分析和语法分析的编译器，包括可以对基于用户输入的正规文法进行词法分析的词法分析器，输出TOKEN表；基于二型文法运用自底向上的LR(1)分析方法，完成对上步输出的程序的语法分析，并输出分析结果，进行报错。编译器词法分析部分首先读取morphology.txt中的正规文法，完成从正规文法到NFA的转换，用子集法，完成NFA到DFA的转换，再根据DFA将读取的source.txt中的源程序生成token列表三元组，包括所在行号，类别，token 内容。编译器语法分析部分首先读取grammar.txt中的二型文法，再进行求FIRST集，计算项目集族，构建分析表，完成LR(1)分析后生成ACTION和GOTO表，从而对词法分析输出的处理结果进行分析，判断其是否被该文法接受，如果出错输出错误。词法分析器词法分析程序的处理逻辑：根据用户输入的正规文法，生成NFA，再确定化生成DFA，根据DFA编写识别token的程序，从头到尾从左至右识别用户输入的源代码，生成token列表（三元组：所在行号，类别，token 内容）。语法分析器—— LR(1)语法分析程序的推荐处理逻辑：根据用户输入的2º型文法，生成Action及Goto表，设计合适的数据结构，判断token序列（用户输入的源程序转换）。媒体计算：手机图像检索系统本项目基于感知哈希的图像检索算法设计了商品图像检索系统，综合运用java和python编程语言，实现了基于Android的商品图像检索及基于Web的系统后台管理。在Android客户端，系统可根据用户上传的商品图片，自动检索并显示出相似的商品图像，还可以查看系统中的商品信息列表，并往图片库中上传商品图片。Web后端管理可让系统管理员上传图片，查看和删除商品信息以及管理员账号的增改删查等基本功能。软件项目管理：考试管理系统基于SSH的CCF管理系统用，利用Myeclipse软件开发，利用Mysql作为后台的数据库，充分利用了SSH和Mysql的优点，利用Window_10作为系统平台。使用Myeclipse 作为系统的开发环境，他提供完善的指令控制语句、类与对象的支持及丰富的数据类型，给开发高性能系统提供的保障，保证了代码的模块化要求，从而提高了代码模块化，非常有利于以后对新系统的扩展与修改。计算机网络：套接字通信算法数组最大最小值​ 分治法矩阵链相乘​ 动态规划旅行商问题​ 分支限界策略或回溯策略图形学组原：CPU根据学习过的硬件课程：计算机逻辑基础、计算机组成原理等，设计一个16位的CPU 。采用语言和原理图结合的方式 ，分模块用语言描述，顶层模块用原理形式。操作系统软件测试软件体系结构：单词本基于顺序批处理思想，实现满足增删改查需求的电子词典软件系统。首先，程序设计体现批处理风格的特点，实现单词的增查删改，在批处理顺序体系结构中，每个数据转换子系统或模块都无法启动其过程，直到其先前的子系统完成其计算为止。数据流将整个数据从一个子系统传送到另一个子系统。系统的主要功能有：对单词的增加、查找、删除、修改。在程序输入文件中输入新加或要删除的单词即可在词典里加入或删除所输入的单词。在查询文件中输入要查询的单词即可在词库中查询到相应的单词；同时也可以在输入文件中输入要改的单词，再输入改成后的单词即可将结果存入词库里。电机控制系统系统采用C/S结构进行设计，宿主机运行客户端程序，目标机上装载有编写的嵌入式系统软件，宿主机和目标机之间通过串口通信信道进行数据传输。宿主机通常是通用个人电脑，其上要运行开发工具软件和客户端软件。目标机即是嵌入式系统机器。1、可以通过PC机远程启动和停止电机旋转；2、基于S3C2440来设计控制器，选用Timer部件来实现直流电机控制；3、可以通过PC机远程对电机进行调速；4、PC机接收控制器返回的占空比参数；5、在控制器的LED显示器上显示控制占空比的参数。在完成以上五个要求的基础上，新加了Modbus协议数据传输功能，能够将上位机传输到下位机的数据进行协议封装，并使用CRC算法进行数据校验。" }, { "title": "用neo4j Graph学算法", "url": "/HeBlog/posts/%E7%94%A8%E5%9B%BE%E5%AD%A6%E7%AE%97%E6%B3%95/", "categories": "Research", "tags": "", "date": "2022-07-03 00:00:00 +0000", "snippet": "用neo4j Graph学算法创建节点CREATE (algorithm:Algorithm {name: &#39;a&#39;})CREATE (structure:Structure {name: &#39;a&#39;})CREATE (problem:Problem {source:&#39;lc&#39;, number:1})创建关系MATCH (a:Structure),(b:Problem)WHERE a.name = &#39;a&#39; AND b.source = &#39;lc&#39; AND b.number = 1CREATE (a)-[r:EXAMPLE_PROBLEM] -&amp;gt; (b)RETURN rMATCH (a:Problem),(b:Problem)WHERE a.source = &#39;lc&#39; AND a.number =1 AND b.source = &#39;b&#39; AND b.number = 1CREATE (a)-[r:PROBLEM_LINK] -&amp;gt; (b)RETURN r" }, { "title": "WolframAlpha", "url": "/HeBlog/posts/WolframAlpha/", "categories": "Research", "tags": "", "date": "2022-06-18 00:00:00 +0000", "snippet": "WolframAlpha官网https://www.wolframalpha.com/ref：https://www.163.com/dy/article/FGUNDTRC054535JN.htmlhttps://reference.wolfram.com/language/guide/MatrixOperations.htmlhttps://reference.wolfram.com/language/tutorial/LinearAlgebraMatrixComputations.html.zh?source=footer示例：向量属性 vector {2, -5, 4}向量点积 {12, 20} . {16, -5}线性相关 linear independence (1, 3, -2), (2, 1, -3), (-3, 6, 3)矩阵 { {6, -7}, {0, 3} }行列式 determinant of { {1,2}, {-1, 2} }秩 rank { {1, 2, 1}, {-2, -3, 1}, {3, 5, 0} }矩阵正交化 transpose orthogonalize {1,1,1}, {1,2,3}, {1,4,9}正定 is { {2, 3}, {4, 8} } a positive definite matrixis { {-2, 3,1}, {3, -8,1},{1,1,-3} } a negative semidefinite matrix行规约 row reduce { {2, 1, 0, -3}, {3, -1, 0, 1}, {1, 4, -2, -5} }逆矩阵 inverse { {1, 1, 2}, {-1, 2, 2}, {3, 2, 3} }伴随 adjugate { {-1, 0}, {0，2} }H ConjugateTranspose特征 eigenvalues { {3,-1},{0,2} } eigenvectors { {7,0,-3},{-9,-2,3},{18,0,-8} }jordan分解 jordan decomp { {1, -2, 0}, {-2, 3, -2}, {0, -2, 1} }svd分解 svd decomposition { {1, -2, 0}, {-2, 3, -2}, {0, -2, 1} }norm Norm[ { {1,2},{3,4} }, “Frobenius” ]Norm[{ {1,2},{3,4} }, Infinity]Norm[ { {1,2},{3,4} }, 1 ]Norm[ { {1,2},{3,4} }, 2 ]矩阵乘 { {2, -1}, {1, 3} } . { {1, 2}, {3, 4} }矩阵幂 matrix power({ {6, -7}, {0, 3} },n)积分 int sinx/x dx, x=0..infinity微分 d/dx x^2 y^4second derivative of x^2 d^2/dt^2(t^2) D[x,x]收敛半径 radius convergence Sum[( ((k+1)*x^k)/(10^k+1)),{k,0,∞}]还原导数 y’=a*Power[ x,a+1]还原幂级数 Sum[k(x^k-1),{k,1,∞}]求幂级数 series[((1-x)^-2)]" }, { "title": "ReID", "url": "/HeBlog/posts/ReID/", "categories": "Research", "tags": "", "date": "2022-05-07 00:00:00 +0000", "snippet": "ReIDPyRetri: PyTorch-based Library for Unsupervised Image Retrieval by Deep Convolutional Neural Networkshttps://github.com/PyRetri/PyRetrihttps://mp.weixin.qq.com/s/_NDw7pFmDB07mliHTA6VYQPerson Re-Identification by Multi-Channel Parts-Based CNN with Improved Triplet Loss Function度量学习、三元组UTS-Person-reID-Practicalhttps://github.com/layumi/Person_reID_baseline_pytorch/tree/master/tutorialDeep Learning for Person Re-identification: A Survey and Outlook-综述GitHub - mangye16/ReID-Survey: Deep Learning for Person Re-identification: A Survey and Outlookhttps://zhuanlan.zhihu.com/p/342249413" }, { "title": "系统常用shell命令", "url": "/HeBlog/posts/%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8shell%E5%91%BD%E4%BB%A4/", "categories": "Help", "tags": "", "date": "2022-01-18 00:00:00 +0000", "snippet": "系统常用shell命令CMD 命令 功能 dir ls xcopy D:\\A F:\\B /T/E 复制D:\\A中的目录结构 dir /s /b &amp;gt; list.txt 导出目录到txt rundll32.exe user32.dll LockWorkStation 锁屏（win+L）     VB 代码 功能 Dim WSHShellSet WSHShell=WScript.CreateObject(&quot;WScript.Shell&quot;)WSHShell.Run &quot;Rundll32.exe user32.dll,LockWorkStation&quot;, 0 锁屏 MAC code func     " }, { "title": "跟李沐大佬读论文", "url": "/HeBlog/posts/%E8%B7%9F%E6%9D%8E%E6%B2%90%E5%A4%A7%E4%BD%AC%E8%AF%BB%E8%AE%BA%E6%96%87/", "categories": "Research", "tags": "", "date": "2021-12-20 00:00:00 +0000", "snippet": "跟李沐大佬读论文方法论pass 1：标题、摘要、结论、图表、实验pass 2：通读、总体流程、文献pass 3：详细、实现TransformerAttention is all you need李沐大佬的讲解位置嵌入：引入位置信息，直接与词嵌入相加注意力机制：给和自身相似的分配更高的权重。QKV是同样的向量复制三份多头：学习到多种在不同空间的特征残差：避免梯度消失 https://www.bilibili.com/video/BV1Di4y1c7Zm?p=4&amp;amp;spm_id_from=pageDriverMask：避免对后面的词进行计算Batch Normal和Layer Normal的区别?​ BN优点:解决内部协变量偏移（有疑？）,缓解梯度饱和​ 缺点：batch_size小时效果差，在RNN中效果差LN：对同一个样本的所有单词进行缩放可参考 视频 文字" }, { "title": "论文阅读笔记-知识图谱", "url": "/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/", "categories": "Research", "tags": "", "date": "2021-12-13 00:00:00 +0000", "snippet": "知识图谱@inproceedings{megdiche2016extensible, title={An extensible linear approach for holistic ontology matching}, author={Megdiche, Imen and Teste, Olivier and Trojahn, Cassia}, booktitle={International Semantic Web Conference}, pages={393--410}, year={2016}, organization={Springer}}-2本体匹配目前的方法：自动匹配和半自动匹配成对匹配–&amp;gt;整体本体匹配（本文）模式级的，基于maximum-weighted graph matching problem概述：In the pre-processing step, we apply element-level matchers and then aggregate the results in order to produce similarities between the entities of the ontologies. In the processing step, we instantiate the different elements of the linear program (decision variables and linear constraints) and then resolve the model by using the CPLEX solver.**pre-processing step: **similarity matrices are computed between each pair of ontologies for classes, object properties and data propertiesLinear Program::speech_balloon:: 说一下自己的理解，这个模型OWL的三种属性进行比对，之后判断本体的相似度    @inproceedings{kimmig2017collective, title={A collective, probabilistic approach to schema mapping}, author={Kimmig, Angelika and Memory, Alex and Getoor, Lise and others}, booktitle={2017 IEEE 33rd International Conference on Data Engineering (ICDE)}, pages={921--932}, year={2017}, organization={IEEE}}-1早期的方法使用元数据(模式约束)和属性对应(也就是模式匹配)来创建与元数据一致的映射，以及等等方法，但这些方法只适用于一致性或完整性的输入。借用probabilistic reasoning techniques，使用probabilistic soft logic (PSL)，可用于知识图谱识别和数据融合本文的的方法Collective Mapping Discovery(CMD)，解决如下挑战： Dirty or Ambiguous Metadata Unexplained Data Data Errors Unknown Values==//todo 公式太复杂了，看不懂，留待之后再看==    @inproceedings{zhu2017iterative, title={Iterative entity alignment via knowledge embeddings}, author={Zhu, Hao and Xie, Ruobing and Liu, Zhiyuan and Sun, Maosong}, booktitle={Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)}, year={2017}}-1code基于TransE的知识嵌入( TransE和PTransE）、联合嵌入（Translation-based Model 将关系嵌入，Linear Transformation Model 实体间的矩阵转换，将一样的实体的模型参数共享）和==迭代对齐（硬对齐：直接将新实体求两实体中值，代入并迭代，软对齐：创建新集合，映射代入)==，最后衡量三部分目标函数和    REGAL: Representation Learning-based Graph AlignmentStep 1: Node Identity Extractionstructural identitydegrees &amp;amp; neighbors up to k hopsattribute-based identityStep 2: Efficient Similarity-based Representationimplicit matrix factorization-based approachStep 2a:Reduced n × p Similarity ComputationStep 2b: From Similarity to RepresentationStep 3: Fast Node Representation Alignment    Bootstrapping Entity Alignment with Knowledge Graph Embedding-2BootEA code 代码很规范一种自举方法来实现基于嵌入的实体对齐。它迭代地将可能的实体对齐标记为训练数据，用于面向学习对齐的KG嵌入。此外，该算法采用对齐编辑方法，以减少迭代过程中的误差积累。通过正例和负例，用limit-based loss，进行嵌入Bootstrapping对齐，每次迭代检查已对齐实体标记，选择能带了更多对齐可能性的实体    @inproceedings{shi2018open, title={Open-world knowledge graph completion}, author={Shi, Baoxu and Weninger, Tim}, booktitle={Thirty-Second AAAI Conference on Artificial Intelligence}, year={2018}}-KGC -1从相关文本中，使用关系依赖内容掩蔽，掩盖不相关的文本，使用完全卷积网络（FCN）提取基于单词的嵌入,将提取的嵌入与KG中的现有实体进行比较，以解析目标实体的排序列表。    Non-translational Alignment for Multi-relational Networks我们建议非转换方法,旨在利用概率模型对齐任务提供更健壮的解决方案,通过探索结构属性以及利用锚项目每个网络到相同的向量空间的过程中学习个体网络的表示:speech_balloon:对于问题的描述很清晰，通过源实体、目标实体、关系的对齐，方法参考性目前不强@inproceedings{zhu2019neighborhood, title={Neighborhood-Aware Attentional Representation for Multilingual Knowledge Graphs.}, author={Zhu, Qiannan and Zhou, Xiaofei and Wu, Jia and Tan, Jianlong and Guo, Li}, booktitle={IJCAI}, pages={1943--1949}, year={2019}}-1通过门控机制获取多跳信息，注意力机制聚集邻居，用GCN学习邻居级别的表示，同时引入关系向量。组件vanilla GCN (Kipf and Welling 2017)R-GCN (Schlichtkrull et al. 2018) 考虑邻居关系（公式不全，核心公式）门控多跳邻居聚合注意力机制聚合损失对齐损失关系损失拓展考虑多跳Learning to Exploit Long-term Relational Dependencies in Knowledge Graphs-实体对齐-RNN -2整体结构图Recurrent skipping networkSkipping Mechanism相比rnn，每次到下一层时，如果这层是对关系的处理，就将上一层节点也加入Biased Random Walkscombine the depth and cross-KG biases 优先深度，优先跨图。对于跨图的路径，论文中说对于输入的两个图，首先构建joint KG，路径是通过seed alignment进行连接，其多少影响模型效果。noise contrastive estimationNeighborhood-Aware Attentional Representation for Multilingual Knowledge Graphs-2在知识图中基于注意力合并邻居级和关系级特征信息，以执行多语言实体对齐任务。@article{das2020probabilistic, title={Probabilistic Case-based Reasoning for Open-World Knowledge Graph Completion}, author={Das, Rajarshi and Godbole, Ameya and Monath, Nicholas and Zaheer, Manzil and McCallum, Andrew}, journal={arXiv preprint arXiv:2010.03548}, year={2020}}-1基于KNN收集知识库中相似实体的推理路径来预测实体的属性，给出可能项的概率。将相似实体先聚类，在桶内查找使用简单的路径统计计算频率和精度。Realistic Re-evaluation of Knowledge Graph Completion Methods: An Experimental Study-1移除不现实的三元组,从而提升知识图谱补全方法的准确度,重新评估方法@inproceedings{yue2020representation, title={Representation-based completion of knowledge graph with open-world data}, author={Yue, Kun and Wang, Jiahui and Li, Xinbai and Hu, Kuang}, booktitle={2020 5th International Conference on Computer and Communication Systems (ICCCS)}, pages={1--8}, year={2020}, organization={IEEE}}-KGC-1将元组关系映射到向量空间，比较相似性A Benchmarking Study of Embedding-based Entity Alignment for Knowledge Graphs-survey-2Knowledge Graph Embedding 方法分类： translational models,e.g., TransE [5], TransH [82], TransR [49] and TransD [33]; semantic matching models, e.g., DistMult [86], ComplEx [76],HolE [54], SimplE [36], RotatE [71] and TuckER [3]; deep models, e.g., ProjE [66], ConvE [13], R-GCN [63], KB-GAN [7] and DSKG [25]. Conventional Entity Alignment 实体对齐方法： One is based on equivalence reasoning mandated by OWL semantics [22, 34]. The other is based on similarity computation, which compares symbolic features of entities [39, 65, 70]. Recent studies also use statistical machine learning [15, 31, 32] and crowdsourcing [96] to improve the accuracy.Embedding-based Entity Alignment Many existing approaches [10, 47, 57, 58, 72,73, 77, 93] employ the translational models (e.g., TransE [5]) to learn entity embeddings for alignment based on relation triples. Some recent approaches [8, 42, 81, 83, 85, 84, 88, 94] employ graph convolutional networks (GCNs) [38, 78]. some approaches incorporate attribute and value embeddings [9, 28, 72, 77, 83, 84, 87, 90]. there are some approaches for (heterogeneous information) network alignment [29, 44, 89] or cross-lingual knowledge projection [56], which may also be modified for entity alignment.Embedding ModuleThe embedding module seeks to encode a KG into a low-dimensional embedding space. relation embedding leverages relational learning techniques to capture KG structures Triple-based embedding captures the local semantics of relation triples ​ ​   ·   denotes the L1- or L2-norm of vectors. Loss marginal ranking loss logistic loss limit-based loss generate negative triples uniform negative sampling truncated sampling Path-based embedding exploits the long-term dependency of relations spanning over relation paths comb(·) is a sequence composition operation such as sum. Neighborhood-based embedding uses the subgraph structure constituted by a large amount of relations between entities with ˆA=A+I and I is an identity matrix.ˆD is the diagonal degree matrix of ˆA. W is the learnable weight matrix. σ(·) is the activation function such as tanh(·). attribute embedding exploits attribute triples of entities. Attribute correlation embedding considers the correlations among attributes. Literal embedding introduces literal values to attribute embedding. Alignment Moduleuses seed alignment as labeled training data to capture the correspondence of entity embeddings. distance metric Cosine, Euclidean and Manhattan distance alignment inference strategy Greedy search collective search Kuhn-Munkres algorithm, heuristic algorithm and stable marriage algorithm Interaction ModeCombination modes Embedding space transformation embeds two KGs in different embedding spaces and learns a transformation matrix M between the two spaces using seed alignment Embedding space calibration encodes two KGs into a unified embedding space. minimizes   e1−e2   for each (e1, e2) to calibrate the embeddings of seed alignment parameter sharing directly configures e1=e2 parameter swapping swaps seed entities in their triples to generate extra triples as supervisionLearning strategies Supervised learning leverages the seed alignment as labeled training data. For embedding space transformation, seed alignment is used to learn the transformation matrix. For space calibration, it is used to let aligned entities have similar embeddings. Semi-supervised learning uses unlabeled data in training, e.g., self-training [73, 93] iteratively proposes new alignment to augment seed alignment. co-training [9] combines two models learned from disjoint entity features and alternately enhances the alignment learning of each other. Unsupervised learningneeds no training data. We have not observed any embedding-based entity alignment approaches using unsupervised learning. Multi-Modal Knowledge Graph Construction and Application: A Survey-2目录多模态KG的定义、发展、意义、挑战，从图像到符号构建KG/从符号到图像构建KGMMKG内应用:实体对齐、连接预测等2 定义和准备工作两种MMKG准备多模态任务 图像字幕 视觉基础 可视化问答 跨模态检索多模态学习 多模态表示：现有的研究要么将多模态投影到一个统一的空间[38]和VGG[39]、ResNet[40]，要么将每个单个模态表示在自己的向量表达空间中，该空间满足某些约束条件，如线性相关性[41]。 多模态翻译。多模态翻译学习从一个模态中的源实例到另一个模态中的目标实例的翻译。基于实例的翻译模型通过字典[37]，[42]在不同的情态之间架起桥梁，而生成性翻译模型则建立了一个更灵活的模型，可以将一种情态转换为另一种情态[43]，[44]。 多模态对齐。多模态对齐旨在发现不同模态之间的对应关系。它既可以直接应用于视觉基础等多模态任务，也可以作为多模态预训练语言模型中的预训练任务 多模态融合。多模态融合指的是将来自不同模态的信息连接起来进行预测的过程[27]，其中应用了各种注意机制，如门控跨模态注意[46]、自底向上注意[47]等，以模拟跨模态模块中不同类型特征之间的交互。5） 多模式合作学习。多模式合作学习旨在通过调整其他模式的资源来缓解某一模式中资源不足的问题[27]。多模态预训练语言模型。基于一个包含文本图像对的大规模无监督多模态数据集，3 构建MMKG结构的本质是将传统KG中的符号知识（包括实体、概念和关系等）与其对应的图像相关联。完成这项任务有两种相反的方法：（1）用KG标记图像；CV社区开发了许多图像标记解决方案，可以利用这些解决方案在图像上标记知识符号（KG）。大多数图像标签解决方案学习从图像内容到各种标签集的映射，包括对象、场景、实体、属性、关系、事件和其他符号。学习过程由人工标注的数据集进行监督，该数据集要求群组工作人员绘制边界框，并用给定的标签标注图像或图像区域，如图2所示。一些著名的基于图像的视觉知识提取系统如表2a所示，可用于通过图像标记构建MMKG。根据要链接的符号类别，将图像链接到符号的过程可分为几个细分任务：视觉实体/概念提取（第3.1.1节）、视觉关系提取（第3.1.2节）和视觉事件提取（第3.1.3节）。（2）用KG标记图像。符号基础是指找到适当的多模态数据项（如图像）以表示传统知识中存在的符号知识的过程。与图像标注方式相比，符号联系方式在MMKG施工中的应用更为广泛。大多数现有MMKG都是以这种方式建造的，如表2b所示。在本小节的其余部分中，我们将介绍在几个细分任务中将符号与图像联系起来的过程：实体联系（第3.2.1节）、概念联系（第3.2.2节）和关系联系（第3.2.3节）。1.基于实体的实体接地旨在将KG中的实体接地到相应的多模态数据，如图像、视频和音频[12]。现有的工作主要侧重于将实体与相应的图像联系起来。挑战。将实体接地到图像的主要挑战如下：1）如何以低成本为实体找到足够多的高质量图像？2） 如何从大量噪声中选择与实体最匹配的图像？进步。有两个主要来源可以找到实体的图像：（1）来自在线百科全书（如维基百科）和（2）通过网络搜索引擎从互联网。2.基于概念的概念基础旨在为视觉概念找到具有代表性的、有区别的和多样的图像。挑战尽管一些视觉上统一的概念（如男人、女人、卡车和狗）也可3.以通过3.2.1中介绍的实体基础方法基础到图像，其他概念的符号基础面临着新的挑战：1）并不是所有的概念都能正确地可视化。例如，非宗教主义者不能基于某个特定的形象。如何区分可视概念和非可视概念？2） 如何从一组相关图像中找到一个可视化概念的代表性图像？请注意，可视化概念的图像可能非常多样。例如，说到公主，人们经常会想到几个不同的形象，比如迪士尼公主、历史电影中的古代公主或新闻中的现代公主。因此，我们必须考虑图像的多样性。进步。为了应对上述挑战，相关研究分为三个任务：可视化概念判断、代表性图像选择和图像多样化。3.基于关系的关系基础是从图像数据语料库或互联网上找到可以代表特定关系的图像。输入可以是该关系的一个或多个三元组，输出应该是该关系最具代表性的图像。挑战。当我们使用三元组作为查询来检索关系的图像时，排名靠前的图像通常与三元组的主语和宾语更相关，但与关系本身无关。如何找到能够反映输入三元组语义关系的图像？进步。现有的关系基础研究主要集中在空间或动作关系上，如左的、上的、骑的和吃的。4 应用1.MMKG内的应用n-MMKG应用指的是在MMKG范围内执行的任务，其中已经学习了实体、概念和关系的嵌入。因此，在介绍MMKG应用程序之前，我们先简要介绍一下MMKG中知识的分布式表示学习，也称为MMKG嵌入。 连接预测 元组分类 实体分类 实体对齐2.MMKG外的应用 多模态实体识别与连接 视觉问答 图文匹配 多模态生成任务 多模式推荐系统6 结论我们是第一个全面调查由文本和图像构建的MMKG的现有工作的人。我们系统地回顾了MMKG施工和应用方面的现有工作。我们比较了主流MMKG的内容和构造方式。我们分析了MMKG结构和应用中不同解决方案的优缺点。我们不仅指出了MMKG建设和应用中现有任务的一些潜在机会，还列出了MMKG建设和应用的一些有希望的未来方向Generating Explanations to Understand and Repair Embedding-based Entity Alignment-Wei Hu-Nanjing University通过局部子图，解释实体对齐的结果GFS: Graph-based Feature Synthesis for Prediction over Relational Databases将表列生成向量，查找关系表，预测标签" }, { "title": "实用机器学习笔记", "url": "/HeBlog/posts/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/", "categories": "Research", "tags": "", "date": "2021-12-13 00:00:00 +0000", "snippet": "实用机器学习笔记-李沐 斯坦福课程主页b站视频1.2 数据获取 数据发现 数据生成 GAN 数据增强 1.3 网页数据抓取tools curl headless、seleniuminspect：确定元素在html中的位置2 数据预处理对于文本数据可采用zip等压缩格式数据清理异常值（outliers ）、基于规则检测、基于模式检测数据变换 Tabular：Normalization Images: cropping(裁剪), downsampling, whitening Videos: clipping, sampling frames Text: stemming, lemmatization, tokenization特征工程3 机器学习监督学习：模型、损失、目标、优化模型分类：决策树、线性模型、核方法、神经网络随机梯度下降SGD​ Mini-batch SGD 超参：batch_size、learn_rate、num_epochs" }, { "title": "其他的相关方向", "url": "/HeBlog/posts/%E5%85%B6%E4%BB%96%E7%9A%84%E7%9B%B8%E5%85%B3%E6%96%B9%E5%90%91/", "categories": "Research", "tags": "", "date": "2021-12-08 00:00:00 +0000", "snippet": "其他的相关方向网页相似性比对TF/IDF （term frequency–inverse document frequency） 根据词频构建新闻的特征向量 –&amp;gt; 余弦距离 手动建立自动建立，构建子分类   计算优化方案（储存长度，只计算非零元素，删除虚词）     效果优化（加权） 信息指纹集合相同判定：一一比较排序后比较推荐系统推荐系统由早期的协同过滤算法发展到 MF 模型、再到之后的 Wide&amp;amp;Deep，以及基于 Network Embedding爬虫ScrapeGraphAI、Crawlee、Kspider" }, { "title": "机器学习中的一些问题", "url": "/HeBlog/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/", "categories": "Research", "tags": "", "date": "2021-11-12 00:00:00 +0000", "snippet": "机器学习中的一些问题基础概念CNN三个特点： 局部感受野（Local Receptive Fields） 共享权值(Shared Weights） 池化（Pooling)问题三层的神经网络就可以拟合任何一个函数mse过于精确？分类的最后一层使用softmax，归一化激活函数作用？得到的网络可以模拟数据更复杂的关系和模式，拥有更好的泛化能力。在实际进行激活函数的选择时： 首先尝试 ReLU，计算简单，速度快。 如果 ReLU 效果欠佳，尝试 Leaky ReLU 或 Maxout 等变种。 尝试 tanh 正切函数（以零点为中心，零点处梯度为1）。 sigmoid / tanh 在 RNN（LSTM、注意力机制等）结构中有所应用，作为门控或者输出概率值。 在浅层神经网络中，如不超过4层的，可选择使用多种激励函数，没有太大的影响。正则化的目的？正则化（regularization）是所有用来降低算法泛化误差（generalization error）的方法的总称。以提升 bias 为代价降低 variance。现实中效果最好的深度学习模型，往往是【复杂的模型（大且深）】+【有效的正则化】。在算法中使用，是防止模型出现过拟合。https://blog.csdn.net/Solo95/article/details/84586794正则化方法（Regularizer） Norm penalty：常用 L1/L2 regularization，理论机制不同，按特征方向重要性，L1 以阈值“削砍”参数分量，L2 “缩水”参数分量；深度学习中的实现方式有【weight decay】和【硬约束（重投影）】两种，各有不足。 L2-regularization 的特殊作用：解决【欠定问题】，调整协方差矩阵（covariance matrix）使其可逆。 Dropout layer 与 batchnorm layer：dropout 本质是一种 ensemble method；dropout 与 batchnorm 用于 regression 时有弊端；同时使用时理论上有冲突。 深度学习的 Early stopping：减少 overfit 之后无意义的训练。 归一化提升模型精度：归一化后，不同维度之间的特征在数值上有一定比较性，可以大大提高分类器的准确性。标准化加速模型收敛：标准化后，最优解的寻优过程明显会变得平缓，更容易正确的收敛到最优解。增加噪声的目的？防止过拟和，提高泛化能力。https://www.zhihu.com/question/275255350/answer/1202608670" }, { "title": "论文阅读笔记", "url": "/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/", "categories": "Research", "tags": "", "date": "2021-09-14 00:00:00 +0000", "snippet": "论文阅读笔记我姑且把论文的阅读方式分为四种：精读3、通读2、略读1、不读，目前结合自己的情况，通读略读的论文放在这里，为了留下一个印象，同时为以后的工作提供参考。精读的论文批注本来是储存在文档上了，但后来发现当自己需要回顾的时候，不能一个一个打开文档，而且自己鸡的记忆，所以还是放在这里供后期回顾总结。本目录以方向分类，以发表时间为序。目录图数据图神经网络知识图谱 （见2021-12-13-知识图谱论文阅读笔记）信息系统分布式内容图Learning Graph Representations with Embedding Propagationhttps://zhuanlan.zhihu.com/p/36027021Forward messages Backward messages与Message Passing Neural Network (MPNN) 的不同： unsupervised combines label embeddings into a joint node reconstructing each node’s representation from neighboring nodes’ representations首先将节点v 的邻居节点的属性向量表达结合起来，重建出节点v 的属性向量表达；接着，将节点 v 本身的属性向量与重建出来的属性向量的差值的梯度，反向传播给它的邻居，来更新邻居的属性向量，不断迭代，直至收敛（或迭代一定次数)。@article{coupette2021graph, title={Graph Similarity Description: How Are These Graphs Similar?}, author={Coupette, Corinna and Vreeken, Jilles}, journal={arXiv preprint arXiv:2105.14364}, year={2021}}-2主要内容：​ MOMO采用联合压缩图，比较图的相似性程度​ BEPPO为单个输入图发现可解释的摘要，GIGI使用它们来揭示它们共享的和特定的结构，从中计算信息相似度得分理论： 非正式相似度描述 论文将图简化为四种基本结构（cliques、Stars、Bicliques、Starcliques），通过邻接矩阵，将节点集大小作为节点得分，连通性约束为边密度。 编码 Graph Under an Individual Model Individual Model Common Model Transformations 度量 Normalized Model Distance\\[\\operatorname{NMD}\\left(G_{1}, G_{2}\\right)=\\frac{L\\left(M_{12}\\right)+L\\left(\\Delta_{1}, \\Delta_{2}\\right)-\\min \\left\\{L\\left(M_{1}\\right), L\\left(M_{2}\\right)\\right\\}}{\\max \\left\\{L\\left(M_{1}\\right), L\\left(M_{2}\\right)\\right\\}}\\] 正式 ​ 算法： 图摘要：BEPPO，算法1 全图查找高度节点，构建基本结构 模型配准：GIGI，算法2 查找公共结构和独特的结构 相关工作​ 图相似性度量，图摘要Tips：​ data, code, and results均可获得数据Deep Learning for Blocking in Entity Matching: A Design Space Exploration-2表匹配High-Dimensional Similarity Query Processing for Data Science-2(1) data models and the way of which we convert raw data (text, images, video, etc.) to high-dimensional data;(2) similarity/distance functions, mainly Hamming distance for binary vectors and Euclidean distance and cosine similarity (angular distance) for real-valued vectors;(3) query types, i.e., search and join queries, or thresholded and top-𝑘 (𝑘-NN) queries, depending on the dimension of categorization; Locality Sensitive Hashing Learning to Hash. Partition-based Methods Neighborhood-based Methods. 𝑘-NN graph [5], hierarchical navigable small world [14], navigating spreading-out graph [6]. https://www.sklearncn.cn/7/#161AdaTyper: Adaptive Semantic Column Type Detection2023输入列，获取列类型header, -using semantic matching.column values, -set of regular expressionand embeddings of columns- basic tree-based machine learning modelObservatory: Characterizing Embeddings of Relational Tables2024 关系属性 Row Order Insignificance行顺序、 Column Order Insignificance列顺序 Join Relationship表join Functional Dependencies函数依赖 数据分布属性 Sample Fidelity Entity Stability Perturbation Robustness Heterogeneous Context LEDD: Large Language Model-Empowered Data Discovery in Data Lakes-清华大学2025we propose LEDD, an end-to-end system with an extensible architecture that leverages LLMs to provide hierarchical global catalogs with semantic meanings and semantic table search for data lakes:speech_balloon:: 这论文能发sigmod？贡献、配图都懒得看，有用再看吧Snoopy: Effective and Efficient Semantic Join Discovery via Proxy Columns- TKDE- Yunjun Gao, zhejiang uSnoopy, an effective and efficient semantic join discovery framework powered by proxy columns. We devise an approximate-graph-matching-based column projection function to capture column-to-proxy-column relationships, ensuring size-unlimited and permutation-invariant column representations. To acquire good proxy columns, we present a rank-aware contrastive learning paradigm to learn proxy column matrices for embedding pre-computing and online query encoding图神经网络@article{wu2020comprehensive, title={A comprehensive survey on graph neural networks}, author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Philip, S Yu}, journal={IEEE transactions on neural networks and learning systems}, volume={32}, number={1}, pages={4--24}, year={2020}, publisher={IEEE}}-survey-2参考文章Graph neural networks vs. network embeddingnetwork embedding：用低维向量表示网络节点，既保留网络拓扑结构又保留节点内容信息GNN ：旨在以端到端方式处理图相关任务的深度学习模型GNN可以通过一个图形自动编码器框架来解决网络嵌入问题。另一方面，网络嵌入还包含其他非深度学习方法，如矩阵分解和随机游动等传统深度学习方法不适用于图的原因： 图是不规则的 图数据之间有关联图神经网络： 图卷积网络（Graph Convolution Networks，GCN） 基于谱（spectral-based）：缺点：需要将整个图加载到内存中以执行图卷积 基于空间（spatial-based） 图注意力网络（Graph Attention Networks） Graph Attention Network (GAT) 优点：自适应地学习邻居的重要性权重 Gated Attention Network (GAAN) 优点：自适应地学习邻居的重要性权重 Graph Attention Model (GAM) 图自编码器（ Graph Autoencoders） 图生成网络（ Graph Generative Networks） 基于GCN Molecular Generative Adversarial Networks (MolGAN) Deep Generative Models of Graphs (DGMG) other GraphRNN NetGAN 图时空网络（Graph Spatial-temporal Networks） Heterogeneous Graph Attention Network然而，对于包含不同类型节点和链接的异构图，它在图神经网络中并没有得到充分的考虑。异构性和丰富的语义信息给异构图神经网络的设计带来了巨大的挑战。现实世界中的图形通常具有多种类型的节点和边，也称为异构信息网络（HIN）信息系统@inproceedings{lian2018high, title={High-order proximity preserving information network hashing}, author={Lian, Defu and Zheng, Kai and Zheng, Vincent W and Ge, Yong and Cao, Longbing and Tsang, Ivor W and Xie, Xing}, booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \\&amp;amp; Data Mining}, pages={1744--1753}, year={2018}}-1信息网络嵌入：基于MF的信息网络哈希（INH-MF）算法来学习能够保持高阶近似的二进制代码。我们还建议汉明子空间学习，每次只更新部分二进制代码，以扩大INH-MFcode分布式@article{stolte2002polaris, title={Polaris: A system for query, analysis, and visualization of multidimensional relational databases}, author={Stolte, Chris and Tang, Diane and Hanrahan, Pat}, journal={IEEE Transactions on Visualization and Computer Graphics}, volume={8}, number={1}, pages={52--65}, year={2002}, publisher={IEEE}}-1https://zhuanlan.zhihu.com/p/409131883https://zhuanlan.zhihu.com/p/388391672湖仓一体化下，分布式查询处理引擎Polaris，包括查询优化和执行调度等方案。==// todo==" }, { "title": "Data lake concept and systems_ a survey", "url": "/HeBlog/posts/Data-lake-concept-and-systems-a-survey/", "categories": "Research", "tags": "", "date": "2021-09-04 00:00:00 +0000", "snippet": "Data lake concept and systems: a surveyAbstract reviews the development, definition, and architectures of data lakes provide a comprehensive overview of research questions for designing and building data lakes classify the existing data lake systems based on their provided functions 1 IntroductionBig data -&amp;gt; ELT, NoSQL -&amp;gt; data lakes2 A brief history of data lakes 2010-2013: Beginnings 2014-2015: Criticisms and further development 2016-present: Prosperity and diversity3 Data lake definitionData Lake: A data lake is a flexible, scalable data storage and management system, which ingests and stores raw data from heterogeneous sources in their original format, and provides query processing and data analytics in an on-the-fly manner.remarks store raw data not only a storage system support on-demand data processing and querying4 Data lake architecturetwo high-level data lake philosophies: pond architecture zone architectureHigh-level architectural philosophies lack technical details about functions, which hampers modular and repeatable implementationsusers data scientists information curators the governance, risk, and compliance team operations team5 Storagepreserve the ingested datasets5.1 File-based storage systemse.g. HDFS: supports a wide range of files5.2 Single data storee.g. Neo4jhas a special application focus on user data of usually relatively small size compared to business scenarios, but higher requirements regarding data privacy5.3 Polystore systemse.g. BigDAWG5.4 Data lakes on cloudse.g. IaaS scale the storage space and computation power dynamically, and in many cases the prices of resources are more economic than on-premises the major cloud vendors provide many additional analytics tools in their product portfolio relying on a cloud platform also implies risks and challenges in some aspects such as data security, data provenance, and fault tolerance6 IngestionIngestion components load data into the lake, and store data into databases or file systems6.1 Metadata extractionTo discovers metadata information that is essential for accessing a datasete.g. GEMMS, DATAMARAN, Skluma6.2 Metadata modelingTo structure and organize the metadata in a formal wayThe majority of such models are either logic-based or graph-structured with more or less formal semantics Generic metadata model Data vault Graph-based metadata model e.g. Aurum 7 MaintenanceTo make the data usable the data lake needs to further process and maintain the raw data7.1 Dataset preparation and organizationstructure and navigate the massive heterogeneous datasets in data lakes7.1.1 Dataset preparatione.g. KAYAK7.1.2 Data lake organizatione.g. GOODS, DS-kNNdata lake organization problem: discovering the optimal structure for users to electively nd the desired dataset in a data lake7.2 Discover related datasetsdata discovery: tries to find a subset of relevant datasets that are similar or complementary to a given dataset in a certain waystep define and extract relatedness signals from tables compute multi-dimensional similarities between attributes, and aggregate them to an overall similarity between tabular datasets7.3 Data integrationTo combining multiple heterogeneous data sources and providing unified data access for usersdata integration techniques: schema matching, schema mapping, query reformulation, entity linkagee.g. Constance7.4 Metadata enrichmentTo further understand and explore a datasete.g. CoreDB, GOODS, Constance7.5 Data quality improvementobtain dependencies from the data in the data lakes, and then use them to improve the data quality.e.g. CLAMS, Constance7.6 Schema evolutionhandling the changes of schemas and integrity constraints8 Explorationchallenging: a large number of ingested sources the heterogeneity of datasolutions: discover the data lakes based on the relatedness of datasets provide a unified query interface for heterogeneous data sources8.1 Query-driven data discoverysearching a data lake based on the measured relatedness (e.g., joinable, unionable) among datasets8.2 Query heterogeneous datae.g. Constance, CoreDB, Ontarioquerying solutions: transform the data in heterogeneous NoSQL stores into relational tables and uses an existing relational database to process the data. e.g. Argo multistore systems providing a SQL-like query language to query NoSQL systems applying a middle-ware to access the multiple NoSQL stores9 Composite metadata managementTo prevent a data lake turn into a “data swamp”9.1 Schema mapping formalismsalgorithmic properties (computational eficiency)metadata-related challenges: Expressive power Structural properties and decidability of reasoning tasks9.2 Data provenance(data lineage)the information of data records10 New directions Machine learning in data lakes Data lakes for data science Stream data lakes11 Summary and outlookSome well-studied problems (e.g., data integration, schema evolution, metadata modeling) need new perspectives and methods in data lakes; while many blank spaces (e.g., stream data lakes, integrate data lakes with machine learning and data science) also call for novel solutions." }, { "title": "知识图谱", "url": "/HeBlog/posts/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/", "categories": "Research", "tags": "", "date": "2021-09-02 00:00:00 +0000", "snippet": "知识图谱http://pelhans.com/ 作者已经写的很全了，就不再造轮子了概览知识表示与知识建模知识抽取知识挖掘知识存储知识推理语义搜索知识问答知识图谱融合==核心内容，非完善版==参考 http://pelhans.com/tags/#Knowledge%20Graph https://github.com/nju-websoft/KnowledgeGraphFusion.git1. 基础知识输入：多个RDF/OWL格式的知识图谱预处理：清洗和后续步骤的准备，包括：语法正规化，数据正规化方法分类 匹配所用特征 知识融合机制 方法适用范围2. 本体匹配3. 实体对齐发现指称真实世界相同对象的不同实例3.1 传统实体对齐方法 等价关系推理 相似度计算 ​ 成对实体对齐 ​ 集体实体对齐 ​ 大规模集体实体对齐 混合方法 3.2 基于 embedding的方法基于翻译模型的方法基于图神经网络的方法4. 知识融合4.1 无监督模型 迭代模型 优化模型 概率图模型无监督模型利用数据冲突和数据源质量估计有监督模型利用特定领域特征和少量标记数据4.2 半监督模型5. 总结多模态知识图谱数据库Answering Visual-Relational Queries inWeb-Extracted Knowledge Graphs 数据集    M5Product: Self-harmonized ContrastiveLearning for E-commercial Multi-modal Pretraining数据集The M5Product dataset is a large-scale multi-modal pre-training dataset with coarse and fine-grained annotations for E-products.• 6 Million multi-modal samples, 5k properties with 24 Million values• 5 modalities-image text table video audio• 6 Million category annotations with 6k classes• Wide data source (1 Million merchants provide)金融数据底座的构建可以包括各类金融实时数据，各类需解析的文档数据、各类非结构化数据以及信息高度浓缩文本。通过庞大的金融垂直类数据为金融大模型提供数据支撑。①各类金实时数据：股票、债券、基金、衍生品、指数等②各类需解析的文档数据：银行流水、财报、年报、ESG报告等③各类非结构化数据：金融新闻、法律、研报、公司信息、银行内外规等④信息高度浓缩文本：金融教材、百科等对于金融垂直领域大模型的构造需要解决的关键问题有如下三点：01多源、异构金融数据金融数字底座构建、金融数据安全共享使用。02金融数据底座与大模型的融合技术，解决通用大模型在垂直领域知识匮乏、知识关联问题，同时实现模型根据数据实时更新、不断迭代。03基于金融科技底座的大模型对于金融科技多领域的应用赋能，展现金融垂直领域涌现能力。ref:https://mp.weixin.qq.com/s/s3GcuubjRdPnusR7vVe5hg 中国工程院院士、复旦大学金融科技研究院院长柴洪峰《大模型赋能金融科技思考与展望》Fusion of Relational and Graph Database Techniques: An Emerging TrendDASFAA 2023 Tutorial关系数据库和图数据库关键技术融合趋势" }, { "title": "图数据库", "url": "/HeBlog/posts/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/", "categories": "Research", "tags": "", "date": "2021-09-02 00:00:00 +0000", "snippet": "图数据库关系数据库中，操作需要大量计算并占用大量内存，成本随着数据量和复杂度成指数级增加。图数据库直接访问连接的节点，无需进行昂贵的搜索和匹配计算。Cypher 是 Neo4j 的声明性图查询语言NoSQL不同分类特点对比 分类 Examples举例 典型应用场景 数据模型 优点 缺点 键值（key-value） Tokyo Cabinet/Tyrant， Redis， Voldemort， Oracle BDB 内容缓存，主要用于处理大量数据的高访问负载，也用于一些日志系统等等。 Key 指向 Value 的键值对，通常用hash table来实现 查找速度快 数据无结构化，通常只被当作字符串或者二进制数据 列存储数据库 Cassandra， HBase， Riak 分布式的文件系统 以列簇式存储，将同一列数据存在一起 查找速度快，可扩展性强，更容易进行分布式扩展 功能相对局限 文档型数据库 CouchDB， MongoDb Web应用（与Key-Value类似，Value是结构化的，不同的是数据库能够了解Value的内容） Key-Value对应的键值对，Value为结构化数据 数据结构要求不严格，表结构可变，不需要像关系型数据库一样需要预先定义表结构 查询性能不高，而且缺乏统一的查询语法。 图形(Graph)数据库 Neo4J， InfoGrid， Infinite Graph 社交网络，推荐系统等。专注于构建关系图谱 图结构 利用图结构相关算法。比如最短路径寻址，N度关系查找等 很多时候需要对整个图做计算才能得出需要的信息，而且这种结构不太好做分布式的集群方案。 Neo4J在Ubuntu中的配置​ 这里两个版本，一个是桌面版，下载后为appimage格式，需要更改权限为可执行，打开即可完成。​ 另一个版本为服务器版本，需要配置到tomcat里，通过网页访问。SpringBoot整合Neo4j免费的数据库 planetscale Railway 限制时间，不能暂停 supabase render：托管 fly.io grafbase：图" }, { "title": "NLP", "url": "/HeBlog/posts/NLP/", "categories": "Research", "tags": "", "date": "2021-08-12 00:00:00 +0000", "snippet": "NLP1 基础知识[通俗理解word2vec](https://www.jianshu.com/p/471d9bfbd72f )[cs224n学习笔记(2)CBOW与Skip-Gram模型](https://zhuanlan.zhihu.com/p/47585825 )从Word Embedding到Bert模型CS224n-notes-and-codes2 BERT源代码从零解读碾压循环神经网络的transformer模型(一)-注意力机制 很好的讲解视频，文档也较全面一文读懂BERT(原理篇) 很棒的一篇博客The Illustrated Transformer https://jalammar.github.io/illustrated-transformer/ 较为优秀的blog，国内大多数博客抄的这篇，但感觉流程逻辑较分散[词向量之BERT](https://zhuanlan.zhihu.com/p/48612853 )[Attention Is All you Need](https://senliuy.gitbook.io/advanced-deep-learning/di-er-zhang-ff1a-xu-lie-mo-xing/attention-is-all-you-need )Bert在NLP各领域的应用进展 一个很好的展望，新颖深入理性幽默，是我喜欢的博主风格hh输入：[CLS] 映射为NSP二分类任务、[SEP] 分句预训练任务：MLM+NSP词向量word2vec skip-gram CBOW 在窗口内预测中间词FastText类似于CBOW，预测标签softmax 归一化处理 较耗时 –&amp;gt; 分层的softmax 根据类别的频率构造霍夫曼树n-gram 字粒度和词粒度" }, { "title": "Ubuntu虚拟机配置", "url": "/HeBlog/posts/Ubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%85%8D%E7%BD%AE/", "categories": "Help", "tags": "", "date": "2021-04-01 00:00:00 +0000", "snippet": "Ubuntu虚拟机配置配置Ubuntu 20.04.2.0 LTS下载链接：​ ubuntu-20.04.2.0-desktop-amd64.isoRecommended system requirements: 2 GHz dual core processor or better 4 GB system memory 25 GB of free hard drive space Internet access is helpful Either a DVD drive or a USB port for the installer mediaUserComputer Name:ubuntuFull Name:developerUserName:devPassword:wRoot Password:rootWithLanguage:Chinese(simplified)Input：中文双拼WithoutgameSoftwareNotepad++IntelliJ IDEA Ultimate 2020.3.3Android StudioPycharm ProfessionalVisual Studio CodeVim +LargeFilexCHMTyporaAnaconda3环境3.26:SSH3.24:docker ,docker-composeJavagitpythonMysql -u root -p root dev devnodejsnpm +cnpmVUE记录如何使用SSH连接虚拟机https://www.jianshu.com/p/91420fa105f6ubuntu设置系统语言为中文 需重启https://jingyan.baidu.com/article/3aed632ec1d120701180916b.htmlubuntu 16.04 设置root用户初始密码https://blog.csdn.net/u012301841/article/details/73692426安装 Githttps://git-scm.com/book/zh/v2/%E8%B5%B7%E6%AD%A5-%E5%AE%89%E8%A3%85-GitUbuntu18.04 安装MySQLhttps://blog.csdn.net/weixx3/article/details/80782479mysql&amp;gt; CREATE USER &#39;dev&#39;@&#39;%&#39; IDENTIFIED BY &#39;dev&#39;;mysql&amp;gt; grant all privileges on *.* to &#39;dev&#39;@&#39;%&#39;;Ubuntu安装vimhttps://blog.csdn.net/lixinghua666/article/details/82289809Ubuntu18.04搭建VUE环境 VSCodehttps://blog.csdn.net/gxgalaxy/article/details/104884128Ubuntu配置java jdk环境配置https://zhuanlan.zhihu.com/p/101920303https://jingyan.baidu.com/article/5552ef47b17e79518ffbc9c8.htmlsudo apt install openjdk-8-jdk-headlesssudo vim /etc/profileexport JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64export JRE_HOME=$JAVA_HOME/jreexport CLASSPATH=$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATHexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATHsudo source /etc/profileubuntu中环境变量文件/etc/profile、.profile、.bashrc、/etc/bash.bashrc之间的区别和联系https://blog.csdn.net/smile_from_2015/article/details/80058351如何在Ubuntu 20.04上安装Anacondahttps://www.myfreax.com/how-to-install-anaconda-on-ubuntu-20-04/https://blog.csdn.net/qq_15192373/article/details/81091098Linux上安装Anaconda图形可视化界面https://blog.csdn.net/qq_39431829/article/details/100165319anaconda-navigatorLinux目录介绍https://blog.csdn.net/luminji/article/details/82256517问题Ubuntu安装MySQL8.0 允许远程访问https://blog.csdn.net/winterking3/article/details/86080434npm ERR! Error: EACCES: permission denied, access ‘/usr/local/lib/node_modules’https://blog.csdn.net/zm_miner/article/details/104637341虚拟内存设置https://www.jianshu.com/p/9722b118e083Ubuntu下error_log过大的终极解决方案 ==不要随便修改文件权限==https://blog.csdn.net/qq_37294163/article/details/106480081解决ubuntu安装软件has install-snap change in progress错误https://blog.csdn.net/u011870280/article/details/80213866snap changessudo snap abort 5" }, { "title": "用ipad编程", "url": "/HeBlog/posts/%E7%94%A8ipad%E7%BC%96%E7%A8%8B/", "categories": "Help", "tags": "", "date": "2021-03-25 00:00:00 +0000", "snippet": "用ipad编程一、开始的策略是通过ipad上传至NextCloud，进行同步，通过Shell进行编译。为了简便开发，学习使用了Shell，进行自动化编译运行。Shellhttps://www.runoob.com/linux/linux-shell.htmlShell_Linux Shell 中实现字符串切割的几种方法https://blog.csdn.net/u010003835/article/details/80750003#！/bin/shecho &quot;Run sh!&quot;#有参数时，执行；无参数跳转if [ $# == 1 ]then FileName=$1 array=(${FileName//./ }) if [[ ${array[1]} = &quot;cpp&quot; ]] then echo &quot;Program cpp:&quot; cd /var/www/html/nextcloud/data/admin/files/ccf/cpp g++ $1 -o ${array[0]} echo -e &quot;--------Run cpp--------&quot; ./${array[0]} cd /root echo &quot;--------Over!--------&quot; elif [[ ${array[1]} = &quot;java&quot; ]] then echo &quot;Program java:&quot; cd /var/www/html/nextcloud/data/admin/files/ccf/java javac $1 echo -e &quot;--------Run java--------&quot; java ${array[0]} echo &quot;--------Over!--------&quot; cd /root else echo &quot;other&quot; fielse cd /var/www/html/nextcloud/data/admin/files/ccf echo &quot;Now at:&quot; pwdfi问题：在网页端不能显示直接在文件系统里添加上的文件，只能显示通过客户端上传的文件。之后想更改设置，让nextcloud自动扫描更心文件，设置时发现无权限。（https://docs.nextcloud.com/server/20/admin_manual/configuration_files/external_storage_configuration_gui.html#enabling-external-storage-support）发现是因为缺php控件posix（https://docs.nextcloud.com/server/20/admin_manual/installation/source_installation.html#prerequisites-for-manual-installation）同时无法定位php和MariaDB的安装位置，这个以后安MySql时要注意，可能会存在版本冲突。二、发现Testastic可以连接命令行，并直接将文件上传至服务器，遂觉得采用此方法。三、Web端vs code最近发现可以配置网页端vs code，但是由于需求不大，故没有配置，GitHub页面" } ]
