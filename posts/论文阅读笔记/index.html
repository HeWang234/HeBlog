<!DOCTYPE html><html lang="zh-CN" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="论文阅读笔记" /><meta property="og:locale" content="zh_CN" /><meta name="description" content="论文阅读笔记" /><meta property="og:description" content="论文阅读笔记" /><link rel="canonical" href="https://hewang234.github.io/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" /><meta property="og:url" content="https://hewang234.github.io/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" /><meta property="og:site_name" content="HeWang" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-09-14T00:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="论文阅读笔记" /><meta name="twitter:site" content="@HeWang234" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-03-02T12:49:52+00:00","datePublished":"2021-09-14T00:00:00+00:00","description":"论文阅读笔记","headline":"论文阅读笔记","mainEntityOfPage":{"@type":"WebPage","@id":"https://hewang234.github.io/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"},"url":"https://hewang234.github.io/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"}</script><title>论文阅读笔记 | HeWang</title><link rel="apple-touch-icon" sizes="180x180" href="/HeBlog/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/HeBlog/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/HeBlog/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/HeBlog/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/HeBlog/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="HeWang"><meta name="application-name" content="HeWang"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/HeBlog/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/HeBlog/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/HeBlog/" alt="avatar" class="mx-auto"> </a></div><div class="site-title mt-3"> <a href="/HeBlog/">HeWang</a></div><div class="site-subtitle font-italic">HeWang's Blog</div></div><ul class="w-100"><li class="nav-item"> <a href="/HeBlog/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>首页</span> </a><li class="nav-item"> <a href="/HeBlog/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>分类</span> </a><li class="nav-item"> <a href="/HeBlog/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>标签</span> </a><li class="nav-item"> <a href="/HeBlog/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>归档</span> </a><li class="nav-item"> <a href="/HeBlog/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>关于</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/HeWang234" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/HeWang234" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['he.wang234','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/HeBlog/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/HeBlog/"> 首页 </a> </span> <span>论文阅读笔记</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> 文章</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="搜索..."> </span> <span id="search-cancel" >取消</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>论文阅读笔记</h1><div class="post-meta text-muted"><div> 作者 <em> <a href="https://twitter.com/sralanlee">HeWang</a> </em></div><div class="d-flex"><div> <span> 发表于 <em class="timeago" data-ts="1631577600" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2021-09-14 </em> </span> <span> 更新于 <em class="timeago" data-ts="1740919792" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2025-03-02 </em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1615 字"> <em>8 分钟</em>阅读</span></div></div></div><div class="post-content"><h1 id="论文阅读笔记">论文阅读笔记</h1><p>我姑且把论文的阅读方式分为四种：精读3、通读2、略读1、不读，目前结合自己的情况，通读略读的论文放在这里，为了留下一个印象，同时为以后的工作提供参考。精读的论文批注本来是储存在文档上了，但后来发现当自己需要回顾的时候，不能一个一个打开文档，而且自己鸡的记忆，所以还是放在这里供后期回顾总结。</p><p>本目录以方向分类，以发表时间为序。</p><h2 id="目录"><span class="mr-2">目录</span><a href="#目录" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p><a href="#图">图</a></p><p><a href="#数据">数据</a></p><p><a href="#图神经网络">图神经网络</a></p><p>知识图谱 （见2021-12-13-知识图谱论文阅读笔记）</p><p><a href="#信息系统">信息系统</a></p><p><a href="#分布式">分布式</a></p><h2 id="内容"><span class="mr-2">内容</span><a href="#内容" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="图"><span class="mr-2"><a id="图"><span class="mr-2">图</a></span><a href="#图" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>Learning Graph Representations with Embedding Propagation
</pre></table></code></div></div><p>https://zhuanlan.zhihu.com/p/36027021</p><p>Forward messages Backward messages</p><p>与Message Passing Neural Network (MPNN) 的不同：</p><ul><li>unsupervised<li>combines label embeddings into a joint node<li>reconstructing each node’s representation from neighboring nodes’ representations</ul><p>首先将节点v 的邻居节点的属性向量表达结合起来，重建出节点v 的属性向量表达；接着，将节点 v 本身的属性向量与重建出来的属性向量的差值的梯度，反向传播给它的邻居，来更新邻居的属性向量，不断迭代，直至收敛（或迭代一定次数)。</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>@article{coupette2021graph,
  title={Graph Similarity Description: How Are These Graphs Similar?},
  author={Coupette, Corinna and Vreeken, Jilles},
  journal={arXiv preprint arXiv:2105.14364},
  year={2021}
}
-2
</pre></table></code></div></div><p><strong>主要内容：</strong></p><p>​ MOMO采用联合压缩图，比较图的相似性程度</p><p>​ BEPPO为单个输入图发现可解释的摘要，GIGI使用它们来揭示它们共享的和特定的结构，从中计算信息相似度得分</p><p><strong>理论：</strong></p><p><img data-src="/HeBlog//assets/images/2021-09-14-论文阅读笔记/image-20210914202729048.png" alt="image-20210914202729048" data-proofer-ignore></p><ol><li><p>非正式相似度描述</p><p>论文将图简化为四种基本结构（cliques、Stars、Bicliques、Starcliques），通过邻接矩阵，将节点集大小作为节点得分，连通性约束为边密度。</p><p><img data-src="/HeBlog//assets/images/2021-09-14-论文阅读笔记/image-20210914202743349.png" alt="image-20210914202743349" data-proofer-ignore></p><li><p>编码</p><ul><li>Graph Under an Individual Model<li>Individual Model<li>Common Model<li>Transformations</ul><li><p>度量</p><p>Normalized Model Distance</p>\[\operatorname{NMD}\left(G_{1}, G_{2}\right)=\frac{L\left(M_{12}\right)+L\left(\Delta_{1}, \Delta_{2}\right)-\min \left\{L\left(M_{1}\right), L\left(M_{2}\right)\right\}}{\max \left\{L\left(M_{1}\right), L\left(M_{2}\right)\right\}}\]<li><p>正式</p><p>​ <img data-src="/HeBlog//assets/images/2021-09-14-论文阅读笔记/主理论.png" alt="主理论" data-proofer-ignore></p></ol><p><strong>算法：</strong></p><ul><li><p>图摘要：BEPPO，算法1</p><p>全图查找高度节点，构建基本结构</p><li><p>模型配准：GIGI，算法2</p><p>查找公共结构和独特的结构</p></ul><p><strong>相关工作</strong></p><p>​ 图相似性度量，图摘要</p><p><strong>Tips：</strong></p><p>​ data, code, and results均可<a href="https://zenodo.org/record/4780912#.YUCSorgzZPY">获得</a></p><h3 id="数据"><span class="mr-2"><a id="数据"><span class="mr-2">数据</a></span><a href="#数据" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>Deep Learning for Blocking in Entity Matching: A Design Space Exploration
-2
</pre></table></code></div></div><p>表匹配</p><p><img data-src="/HeBlog//assets/images/2021-09-14-论文阅读笔记/image-20211230142632301.png" alt="image-20211230142632301" data-proofer-ignore></p><p><img data-src="/HeBlog//assets/images/2021-09-14-论文阅读笔记/image-20211230151603140.png" alt="image-20211230151603140" data-proofer-ignore></p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>High-Dimensional Similarity Query Processing for Data Science
-2
</pre></table></code></div></div><p>(1) data models and the way of which we convert raw data (text, images, video, etc.) to high-dimensional data;</p><p>(2) similarity/distance functions, mainly Hamming distance for binary vectors and Euclidean distance and cosine similarity (angular distance) for real-valued vectors;</p><p>(3) query types, i.e., search and join queries, or thresholded and top-𝑘 (𝑘-NN) queries, depending on the dimension of categorization;</p><ol><li><p>Locality Sensitive Hashing</p><li><p>Learning to Hash.</p><li><p>Partition-based Methods</p><li><p>Neighborhood-based Methods.</p><ol><li><p>𝑘-NN graph [5],</p><ol><li>hierarchical navigable small world [14],<li>navigating spreading-out graph [6].</ol></ol></ol><p>https://www.sklearncn.cn/7/#161</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>AdaTyper: Adaptive Semantic Column Type Detection
2023
</pre></table></code></div></div><p>输入列，获取列类型</p><p>header, -using semantic matching.</p><p>column values, -set of regular expression</p><p>and embeddings of columns- basic tree-based machine learning model</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>Observatory: Characterizing Embeddings of Relational Tables
2024
</pre></table></code></div></div><ol><li>关系属性<ol><li>Row Order Insignificance行顺序、<li>Column Order Insignificance列顺序<li>Join Relationship表join<li>Functional Dependencies函数依赖</ol><li>数据分布属性<ol><li>Sample Fidelity<li>Entity Stability<li>Perturbation Robustness<li>Heterogeneous Context</ol></ol><p><img data-src="/HeBlog//assets/images/2021-09-14-论文阅读笔记/image-20240206160318273.png" alt="image-20240206160318273" data-proofer-ignore></p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>LEDD: Large Language Model-Empowered Data Discovery in Data Lakes
-清华大学
2025
</pre></table></code></div></div><p>we propose LEDD, an end-to-end system with an extensible architecture that leverages LLMs to provide hierarchical global catalogs with semantic meanings and semantic table search for data lakes</p><p>:speech_balloon:: 这论文能发sigmod？贡献、配图都懒得看，有用再看吧</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>Snoopy: Effective and Efficient Semantic Join Discovery via Proxy Columns
- TKDE
- Yunjun Gao, zhejiang u
</pre></table></code></div></div><p>Snoopy, an effective and efficient semantic join discovery framework powered by proxy columns. We devise an approximate-graph-matching-based column projection function to capture column-to-proxy-column relationships, ensuring size-unlimited and permutation-invariant column representations. To acquire good proxy columns, we present a rank-aware contrastive learning paradigm to learn proxy column matrices for embedding pre-computing and online query encoding</p><p><img data-src="/HeBlog//assets/images/2021-09-14-论文阅读笔记/image-20250302204907810.png" alt="image-20250302204907810" data-proofer-ignore></p><h3 id="图神经网络"><span class="mr-2"><a id="图神经网络"><span class="mr-2">图神经网络</a></span><a href="#图神经网络" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre>@article{wu2020comprehensive,
  title={A comprehensive survey on graph neural networks},
  author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Philip, S Yu},
  journal={IEEE transactions on neural networks and learning systems},
  volume={32},
  number={1},
  pages={4--24},
  year={2020},
  publisher={IEEE}
}
-survey
-2
</pre></table></code></div></div><p><a href="https://zhuanlan.zhihu.com/p/75307407?utm_source=wechat_session&amp;utm_medium=social&amp;utm_oi=1070349627613564928&amp;utm_campaign=shareopn">参考文章</a></p><p>Graph neural networks vs. network embedding</p><p>network embedding：用低维向量表示网络节点，既保留网络拓扑结构又保留节点内容信息</p><p>GNN ：旨在以端到端方式处理图相关任务的深度学习模型</p><p>GNN可以通过一个图形自动编码器框架来解决网络嵌入问题。另一方面，网络嵌入还包含其他非深度学习方法，如矩阵分解和随机游动等</p><p>传统深度学习方法不适用于图的原因：</p><ul><li>图是不规则的<li>图数据之间有关联</ul><p>图神经网络：</p><ol><li><p>图卷积网络（Graph Convolution Networks，GCN）</p><ul><li>基于谱（spectral-based）：缺点：需要将整个图加载到内存中以执行图卷积<li>基于空间（spatial-based）</ul><li><p>图注意力网络（Graph Attention Networks）</p><ul><li><p>Graph Attention Network (GAT) 优点：自适应地学习邻居的重要性权重</p><li><p>Gated Attention Network (GAAN) 优点：自适应地学习邻居的重要性权重</p><li><p>Graph Attention Model (GAM)</p></ul><li><p>图自编码器（ Graph Autoencoders）</p><li><p>图生成网络（ Graph Generative Networks）</p><ul><li><p>基于GCN</p><ul><li>Molecular Generative Adversarial Networks (MolGAN)<li>Deep Generative Models of Graphs (DGMG)</ul><li><p>other</p><ul><li><p>GraphRNN</p><li><p>NetGAN</p></ul></ul><li><p>图时空网络（Graph Spatial-temporal Networks）</p></ol><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>Heterogeneous Graph Attention Network
</pre></table></code></div></div><p>然而，对于包含不同类型节点和链接的异构图，它在图神经网络中并没有得到充分的考虑。异构性和丰富的语义信息给异构图神经网络的设计带来了巨大的挑战。</p><p>现实世界中的图形通常具有多种类型的节点和边，也称为异构信息网络（HIN）</p><h3 id="信息系统"><span class="mr-2"><a id="信息系统"><span class="mr-2">信息系统</a></span><a href="#信息系统" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>@inproceedings{lian2018high,
  title={High-order proximity preserving information network hashing},
  author={Lian, Defu and Zheng, Kai and Zheng, Vincent W and Ge, Yong and Cao, Longbing and Tsang, Ivor W and Xie, Xing},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \&amp; Data Mining},
  pages={1744--1753},
  year={2018}
}
-1
</pre></table></code></div></div><p>信息网络嵌入：基于MF的信息网络哈希（INH-MF）算法来学习能够保持高阶近似的二进制代码。我们还建议汉明子空间学习，每次只更新部分二进制代码，以扩大INH-MF</p><p><a href="https://github.com/DefuLian/network">code</a></p><h3 id="分布式"><span class="mr-2"><a id="分布式"><span class="mr-2">分布式</a></span><a href="#分布式" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre>@article{stolte2002polaris,
  title={Polaris: A system for query, analysis, and visualization of multidimensional relational databases},
  author={Stolte, Chris and Tang, Diane and Hanrahan, Pat},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  volume={8},
  number={1},
  pages={52--65},
  year={2002},
  publisher={IEEE}
}
-1
</pre></table></code></div></div><p>https://zhuanlan.zhihu.com/p/409131883</p><p>https://zhuanlan.zhihu.com/p/388391672</p><p>湖仓一体化下，分布式查询处理引擎Polaris，包括查询优化和执行调度等方案。</p><p>==// todo==</p><p><img data-src="/HeBlog//assets/images/2021-09-14-论文阅读笔记/Snipaste_2021-09-15_20-39-03.png" alt="image-20210914202729048" data-proofer-ignore></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/HeBlog//categories/research/'>Research</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> 本文由作者按照 <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> 进行授权</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">分享</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=论文阅读笔记 - HeWang&amp;url=https://hewang234.github.io/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=论文阅读笔记 - HeWang&amp;u=https://hewang234.github.io/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https://hewang234.github.io/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/&amp;text=论文阅读笔记 - HeWang" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="分享链接" data-title-succeed="链接已复制！"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">最近更新</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E5%A4%9A%E6%A8%A1%E6%80%81/">论文阅读笔记-多模态</a><li><a href="/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a><li><a href="/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E9%87%91%E8%9E%8D/">论文阅读笔记-金融</a><li><a href="/HeBlog/posts/%E9%87%91%E8%9E%8D%E7%9F%A5%E8%AF%86/">金融知识</a><li><a href="/HeBlog/posts/%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8shell%E5%91%BD%E4%BB%A4/">系统常用shell命令</a></ul></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">文章内容</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>相关文章</h3><div class="card-deck mb-4"><div class="card"> <a href="/HeBlog/posts/%E8%B7%9F%E6%9D%8E%E6%B2%90%E5%A4%A7%E4%BD%AC%E8%AF%BB%E8%AE%BA%E6%96%87/"><div class="card-body"> <em class="timeago small" data-ts="1639958400" > 2021-12-20 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>跟李沐大佬读论文</h3><div class="text-muted small"><p> 跟李沐大佬读论文 方法论 pass 1：标题、摘要、结论、图表、实验 pass 2：通读、总体流程、文献 pass 3：详细、实现 Transformer Attention is all you need 李沐大佬的讲解 位置嵌入：引入位置信息，直接与词嵌入相加 注意力机制：给和自身相似的分配更高的权重。QKV是同样的向量复制三份 多头：学习到多种在不同空间的特征 残...</p></div></div></a></div><div class="card"> <a href="/HeBlog/posts/ReID/"><div class="card-body"> <em class="timeago small" data-ts="1651881600" > 2022-05-07 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ReID</h3><div class="text-muted small"><p> ReID 1 PyRetri: PyTorch-based Library for Unsupervised Image Retrieval by Deep Convolutional Neural Networks https://github.com/PyRetri/PyRetri https://mp.weixin.qq.com/s/_NDw7pFmDB07mliHTA6VYQ...</p></div></div></a></div><div class="card"> <a href="/HeBlog/posts/WolframAlpha/"><div class="card-body"> <em class="timeago small" data-ts="1655510400" > 2022-06-18 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>WolframAlpha</h3><div class="text-muted small"><p> WolframAlpha 官网 https://www.wolframalpha.com/ ref： https://www.163.com/dy/article/FGUNDTRC054535JN.html https://reference.wolfram.com/language/guide/MatrixOperations.html https://reference.wo...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/HeBlog//posts/Data-lake-concept-and-systems-a-survey/" class="btn btn-outline-primary" prompt="上一篇"><p>Data lake concept and systems_ a survey</p></a> <a href="/HeBlog//posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/" class="btn btn-outline-primary" prompt="下一篇"><p>机器学习中的一些问题</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://twitter.com/sralanlee">HeWang</a>. <span data-toggle="tooltip" data-placement="top" title="除非另有说明，本网站上的博客文章均由作者按照知识共享署名 4.0 国际 (CC BY 4.0) 许可协议进行授权。">保留部分权利。</span></p></div><div class="footer-right"><p class="mb-0"> 本站由 <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> 生成，采用 <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> 主题。</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/HeBlog/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">搜索结果为空</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/zh.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/HeBlog/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/HeBlog/app.js"></script>
