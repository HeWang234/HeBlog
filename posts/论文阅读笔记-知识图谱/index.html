<!DOCTYPE html><html lang="zh-CN" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="论文阅读笔记-知识图谱" /><meta property="og:locale" content="zh_CN" /><meta name="description" content="知识图谱" /><meta property="og:description" content="知识图谱" /><link rel="canonical" href="https://hewang234.github.io/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" /><meta property="og:url" content="https://hewang234.github.io/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" /><meta property="og:site_name" content="HeWang" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-12-13T00:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="论文阅读笔记-知识图谱" /><meta name="twitter:site" content="@HeWang234" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-02-21T03:11:59+00:00","datePublished":"2021-12-13T00:00:00+00:00","description":"知识图谱","headline":"论文阅读笔记-知识图谱","mainEntityOfPage":{"@type":"WebPage","@id":"https://hewang234.github.io/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},"url":"https://hewang234.github.io/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"}</script><title>论文阅读笔记-知识图谱 | HeWang</title><link rel="apple-touch-icon" sizes="180x180" href="/HeBlog/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/HeBlog/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/HeBlog/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/HeBlog/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/HeBlog/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="HeWang"><meta name="application-name" content="HeWang"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/HeBlog/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/HeBlog/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/HeBlog/" alt="avatar" class="mx-auto"> </a></div><div class="site-title mt-3"> <a href="/HeBlog/">HeWang</a></div><div class="site-subtitle font-italic">HeWang's Blog</div></div><ul class="w-100"><li class="nav-item"> <a href="/HeBlog/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>首页</span> </a><li class="nav-item"> <a href="/HeBlog/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>分类</span> </a><li class="nav-item"> <a href="/HeBlog/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>标签</span> </a><li class="nav-item"> <a href="/HeBlog/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>归档</span> </a><li class="nav-item"> <a href="/HeBlog/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>关于</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/HeWang234" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/HeWang234" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['he.wang234','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/HeBlog/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/HeBlog/"> 首页 </a> </span> <span>论文阅读笔记-知识图谱</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> 文章</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="搜索..."> </span> <span id="search-cancel" >取消</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>论文阅读笔记-知识图谱</h1><div class="post-meta text-muted"><div> 作者 <em> <a href="https://twitter.com/sralanlee">HeWang</a> </em></div><div class="d-flex"><div> <span> 发表于 <em class="timeago" data-ts="1639353600" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2021-12-13 </em> </span> <span> 更新于 <em class="timeago" data-ts="1708485119" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2024-02-21 </em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="4061 字"> <em>22 分钟</em>阅读</span></div></div></div><div class="post-content"><h3 id="知识图谱"><span class="mr-2"><a id="知识图谱"><span class="mr-2">知识图谱</a></span><a href="#知识图谱" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre>@inproceedings{megdiche2016extensible,
  title={An extensible linear approach for holistic ontology matching},
  author={Megdiche, Imen and Teste, Olivier and Trojahn, Cassia},
  booktitle={International Semantic Web Conference},
  pages={393--410},
  year={2016},
  organization={Springer}
}
-2
</pre></table></code></div></div><p>本体匹配</p><p>目前的方法：自动匹配和半自动匹配</p><p>成对匹配–&gt;整体本体匹配（本文）</p><p>模式级的，基于maximum-weighted graph matching problem</p><p>概述：</p><p>In the pre-processing step, we apply element-level matchers and then aggregate the results in order to produce similarities between the entities of the ontologies. In the processing step, we instantiate the different elements of the linear program (decision variables and linear constraints) and then resolve the model by using the CPLEX solver.</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20210929181638803.png" alt="image-20210929181638803" data-proofer-ignore></p><p>**pre-processing step: **similarity matrices are computed between each pair of ontologies for classes, object properties and data properties</p><p><strong>Linear Program:</strong></p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20210929182131780.png" alt="image-20210929182131780" data-proofer-ignore></p><p>:speech_balloon:: 说一下自己的理解，这个模型OWL的三种属性进行比对，之后判断本体的相似度</p><p>    </p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre>@inproceedings{kimmig2017collective,
  title={A collective, probabilistic approach to schema mapping},
  author={Kimmig, Angelika and Memory, Alex and Getoor, Lise and others},
  booktitle={2017 IEEE 33rd International Conference on Data Engineering (ICDE)},
  pages={921--932},
  year={2017},
  organization={IEEE}
}
-1
</pre></table></code></div></div><p>早期的方法使用元数据(模式约束)和属性对应(也就是模式匹配)来创建与元数据一致的映射，以及等等方法，但这些方法只适用于一致性或完整性的输入。</p><p>借用probabilistic reasoning techniques，使用probabilistic soft logic (PSL)，可用于知识图谱识别和数据融合</p><p>本文的的方法Collective Mapping Discovery(CMD)，解决如下挑战：</p><ul><li>Dirty or Ambiguous Metadata<li>Unexplained Data<li>Data Errors<li>Unknown Values</ul><p>==//todo 公式太复杂了，看不懂，留待之后再看==</p><p>    </p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>@inproceedings{zhu2017iterative,
  title={Iterative entity alignment via knowledge embeddings},
  author={Zhu, Hao and Xie, Ruobing and Liu, Zhiyuan and Sun, Maosong},
  booktitle={Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)},
  year={2017}
}
-1
</pre></table></code></div></div><p><a href="https://github.com/thunlp/IEAJKE">code</a></p><p>基于TransE的知识嵌入( TransE和PTransE）、联合嵌入（Translation-based Model 将关系嵌入<img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211218200517915.png" alt="image-20211218200517915" data-proofer-ignore>，Linear Transformation Model 实体间的矩阵转换<img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211218200551225.png" alt="image-20211218200551225" data-proofer-ignore>，将一样的实体的模型参数共享）和==迭代对齐（硬对齐：直接将新实体求两实体中值，代入并迭代，软对齐：创建新集合，映射代入)==，最后衡量三部分目标函数和</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211218202810763.png" alt="image-20211218202810763" data-proofer-ignore></p><p>    </p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>REGAL: Representation Learning-based Graph Alignment
</pre></table></code></div></div><p><strong>Step 1: Node Identity Extraction</strong></p><p>structural identity</p><p>degrees &amp; neighbors up to k hops</p><p>attribute-based identity</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211220144302861.png" alt="image-20211220144302861" data-proofer-ignore></p><p><strong>Step 2: Efficient Similarity-based Representation</strong></p><p>implicit matrix factorization-based approach</p><p>Step 2a:Reduced n × p Similarity Computation</p><p>Step 2b: From Similarity to Representation</p><p><strong>Step 3: Fast Node Representation Alignment</strong></p><p>    </p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>Bootstrapping Entity Alignment with Knowledge Graph Embedding
-2
</pre></table></code></div></div><p><a href="https://github.com/nju-websoft/BootEA">BootEA code</a> 代码很规范</p><p>一种自举方法来实现基于嵌入的实体对齐。它迭代地将可能的实体对齐标记为训练数据，用于面向学习对齐的KG嵌入。此外，该算法采用对齐编辑方法，以减少迭代过程中的误差积累。</p><p>通过正例和负例，用limit-based loss，进行嵌入</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211220153020064.png" alt="image-20211220153020064" data-proofer-ignore></p><p>Bootstrapping对齐，每次迭代检查已对齐实体标记，选择能带了更多对齐可能性的实体</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211220154542225.png" alt="image-20211220154542225" data-proofer-ignore></p><p>    </p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>@inproceedings{shi2018open,
  title={Open-world knowledge graph completion},
  author={Shi, Baoxu and Weninger, Tim},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}
-KGC 
-1
</pre></table></code></div></div><p>从相关文本中，使用关系依赖内容掩蔽，掩盖不相关的文本，使用完全卷积网络（FCN）提取基于单词的嵌入,将提取的嵌入与KG中的现有实体进行比较，以解析目标实体的排序列表。</p><p>    </p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>Non-translational Alignment for Multi-relational Networks
</pre></table></code></div></div><p>我们建议非转换方法,旨在利用概率模型对齐任务提供更健壮的解决方案,通过探索结构属性以及利用锚项目每个网络到相同的向量空间的过程中学习个体网络的表示</p><p>:speech_balloon:对于问题的描述很清晰，通过源实体、目标实体、关系的对齐，方法参考性目前不强</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>@inproceedings{zhu2019neighborhood,
  title={Neighborhood-Aware Attentional Representation for Multilingual Knowledge Graphs.},
  author={Zhu, Qiannan and Zhou, Xiaofei and Wu, Jia and Tan, Jianlong and Guo, Li},
  booktitle={IJCAI},
  pages={1943--1949},
  year={2019}
}
-1
</pre></table></code></div></div><p>通过门控机制获取多跳信息，注意力机制聚集邻居，用GCN学习邻居级别的表示，同时引入关系向量。</p><p><strong>组件</strong></p><p>vanilla GCN (Kipf and Welling 2017)</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211219114142497.png" alt="image-20211219114142497" data-proofer-ignore></p><p>R-GCN (Schlichtkrull et al. 2018) 考虑邻居关系</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211219114157326.png" alt="image-20211219114157326" data-proofer-ignore></p><p>（公式不全，核心公式）</p><p>门控多跳邻居聚合</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211219113906327.png" alt="image-20211219113906327" data-proofer-ignore></p><p>注意力机制</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211219113947223.png" alt="image-20211219113947223" data-proofer-ignore></p><p><strong>聚合</strong></p><p>损失</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211219120022714.png" alt="image-20211219120022714" data-proofer-ignore></p><p>对齐损失</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211219115944915.png" alt="image-20211219115944915" data-proofer-ignore></p><p>关系损失</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211219120013548.png" alt="image-20211219120013548" data-proofer-ignore></p><p><strong>拓展</strong></p><p>考虑多跳</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211219120045693.png" alt="image-20211219120045693" data-proofer-ignore></p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>Learning to Exploit Long-term Relational Dependencies in Knowledge Graphs
-实体对齐
-RNN 
-2
</pre></table></code></div></div><p>整体结构图</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211125174917691.png" alt="image-20211125174917691" data-proofer-ignore></p><p><strong>Recurrent skipping network</strong></p><p>Skipping Mechanism</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211125174945677.png" alt="image-20211125174945677" data-proofer-ignore></p><p>相比rnn，每次到下一层时，如果这层是对关系的处理，就将上一层节点也加入</p><p><strong>Biased Random Walks</strong></p><p>combine the depth and cross-KG biases 优先深度，优先跨图。</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211125180226398.png" alt="image-20211125180226398" data-proofer-ignore></p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211125175311365.png" alt="image-20211125175311365" data-proofer-ignore></p><p>对于跨图的路径，论文中说对于输入的两个图，首先构建joint KG，路径是通过seed alignment进行连接，其多少影响模型效果。</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211206220107766.png" alt="image-20211206220107766" data-proofer-ignore></p><p><strong>noise contrastive estimation</strong></p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211125180023674.png" alt="image-20211125180023674" data-proofer-ignore></p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>Neighborhood-Aware Attentional Representation for Multilingual Knowledge Graphs
-2
</pre></table></code></div></div><p>在知识图中基于注意力合并邻居级和关系级特征信息，以执行多语言实体对齐任务。</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211219135846923.png" alt="image-20211219135846923" data-proofer-ignore></p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>@article{das2020probabilistic,
  title={Probabilistic Case-based Reasoning for Open-World Knowledge Graph Completion},
  author={Das, Rajarshi and Godbole, Ameya and Monath, Nicholas and Zaheer, Manzil and McCallum, Andrew},
  journal={arXiv preprint arXiv:2010.03548},
  year={2020}
}

-1
</pre></table></code></div></div><p>基于KNN收集知识库中相似实体的推理路径来预测实体的属性，给出可能项的概率。将相似实体先聚类，在桶内查找使用简单的路径统计计算频率和精度。</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>Realistic Re-evaluation of Knowledge Graph Completion Methods: An Experimental Study
-1
</pre></table></code></div></div><p>移除不现实的三元组,从而提升知识图谱补全方法的准确度,重新评估方法</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre>@inproceedings{yue2020representation,
  title={Representation-based completion of knowledge graph with open-world data},
  author={Yue, Kun and Wang, Jiahui and Li, Xinbai and Hu, Kuang},
  booktitle={2020 5th International Conference on Computer and Communication Systems (ICCCS)},
  pages={1--8},
  year={2020},
  organization={IEEE}
}
-KGC
-1
</pre></table></code></div></div><p>将元组关系映射到向量空间，比较相似性</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>A Benchmarking Study of Embedding-based Entity Alignment for Knowledge Graphs
-survey
-2
</pre></table></code></div></div><p><strong>Knowledge Graph Embedding</strong> 方法分类：</p><ol><li><p>translational models,e.g., TransE [5], TransH [82], TransR [49] and TransD [33];</p><li><p>semantic matching models, e.g., DistMult [86], ComplEx [76],HolE [54], SimplE [36], RotatE [71] and TuckER [3];</p><li><p>deep models, e.g., ProjE [66], ConvE [13], R-GCN [63], KB-GAN [7] and DSKG [25].</p></ol><p>Conventional <strong>Entity Alignment</strong> 实体对齐方法：</p><ul><li><p>One is based on <strong>equivalence reasoning</strong> mandated by OWL semantics [22, 34].</p><li><p>The other is based on <strong>similarity computation</strong>, which compares symbolic features of entities [39, 65, 70].</p></ul><p>Recent studies also use statistical <strong>machine learning</strong> [15, 31, 32] and <strong>crowdsourcing</strong> [96] to improve the accuracy.</p><p><strong>Embedding-based Entity Alignment</strong></p><ul><li><p>Many existing approaches [10, 47, 57, 58, 72,73, 77, 93] employ the <strong>translational models</strong> (e.g., TransE [5]) to learn entity embeddings for alignment based on relation triples.</p><li><p>Some recent approaches [8, 42, 81, 83, 85, 84, 88, 94] employ <strong>graph convolutional networks</strong> (GCNs) [38, 78].</p><li><p>some approaches <strong>incorporate attribute and value embeddings</strong> [9, 28, 72, 77, 83, 84, 87, 90].</p></ul><p>there are some approaches for (heterogeneous information) network alignment [29, 44, 89] or cross-lingual knowledge projection [56], which may also be modified for entity alignment.</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211214164322226.png" alt="image-20211214164322226" data-proofer-ignore></p><h4 id="embedding-module"><span class="mr-2"><strong>Embedding Module</strong></span><a href="#embedding-module" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4></h4><p>The embedding module seeks to encode a KG into a low-dimensional embedding space.</p><ul><li><p><strong>relation embedding</strong> leverages relational learning techniques to capture KG structures</p><ol><li><p><strong>Triple-based embedding</strong> captures the local semantics of relation triples</p><p>​ <img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211214152726041.png" alt="image-20211214152726041" data-proofer-ignore></p><div class="table-wrapper"><table><tbody><tr><td>​<td> <td>·<td> <td>denotes the L1- or L2-norm of vectors.</table></div><p>Loss</p><ul><li><p>marginal ranking loss</p><li><p>logistic loss</p><li><p>limit-based loss</p></ul><p>generate negative triples</p><ul><li><p>uniform negative sampling</p><li><p>truncated sampling</p></ul><li><p><strong>Path-based embedding</strong> exploits the long-term dependency of relations spanning over relation paths</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211214154257216.png" alt="image-20211214154257216" data-proofer-ignore></p><p>comb(·) is a sequence composition operation such as sum.</p><ol><li><p><strong>Neighborhood-based embedding</strong> uses the subgraph structure constituted by a large amount of relations between entities</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20211214160145812.png" alt="image-20211214160145812" data-proofer-ignore></p><p>with ˆA=A+I and I is an identity matrix.ˆD is the diagonal degree matrix of ˆA. W is the learnable weight matrix. σ(·) is the activation function such as tanh(·).</p></ol></ol><li><p><strong>attribute embedding</strong> exploits attribute triples of entities.</p><ol><li><strong>Attribute correlation embedding</strong> considers the correlations among attributes.<li><strong>Literal embedding</strong> introduces literal values to attribute embedding.</ol></ul><h4 id="alignment-module"><span class="mr-2">Alignment Module</span><a href="#alignment-module" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4></h4><p>uses seed alignment as labeled training data to capture the correspondence of entity embeddings.</p><ul><li><p>distance metric</p><p>Cosine, Euclidean and Manhattan distance</p><li><p>alignment inference strategy</p><ul><li><p>Greedy search</p><li><p>collective search</p><p>Kuhn-Munkres algorithm, heuristic algorithm and stable marriage algorithm</p></ul></ul><h4 id="interaction-mode"><span class="mr-2">Interaction Mode</span><a href="#interaction-mode" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4></h4><p><strong>Combination modes</strong></p><ul><li><strong>Embedding space transformation</strong> embeds two KGs in different embedding spaces and learns a transformation matrix M between the two spaces using seed alignment<li><div class="table-wrapper"><table><tbody><tr><td><strong>Embedding space calibration</strong> encodes two KGs into a unified embedding space. minimizes<td> <td>e1−e2<td> <td>for each (e1, e2) to calibrate the embeddings of seed alignment</table></div><li><strong>parameter sharing</strong> directly configures e1=e2<li><strong>parameter swapping</strong> swaps seed entities in their triples to generate extra triples as supervision</ul><p><strong>Learning strategies</strong></p><ul><li><p><strong>Supervised learning</strong> leverages the seed alignment as labeled training data.</p><ul><li>For embedding space transformation, seed alignment is used to learn the transformation matrix.<li>For space calibration, it is used to let aligned entities have similar embeddings.</ul><li><p><strong>Semi-supervised learning</strong> uses unlabeled data in training, e.g.,</p><ul><li>self-training [73, 93] iteratively proposes new alignment to augment seed alignment.<li>co-training [9] combines two models learned from disjoint entity features and alternately enhances the alignment learning of each other.</ul><li><p><strong>Unsupervised learningneeds</strong> no training data.</p><p>We have <strong>not</strong> observed any embedding-based entity alignment approaches using unsupervised learning.</p></ul><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>Multi-Modal Knowledge Graph Construction and Application: A Survey
-2
</pre></table></code></div></div><p><strong>目录</strong></p><p>多模态KG的定义、发展、意义、挑战，</p><p>从图像到符号构建KG/从符号到图像构建KG</p><p>MMKG内应用:实体对齐、连接预测等</p><p><strong>2 定义和准备工作</strong></p><p>两种MMKG</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20220405183115814.png" alt="image-20220405183115814" data-proofer-ignore></p><p><strong>准备</strong></p><p>多模态任务</p><ol><li>图像字幕<li>视觉基础<li>可视化问答<li>跨模态检索</ol><p>多模态学习</p><ol><li>多模态表示：现有的研究要么将多模态投影到一个统一的空间[38]和VGG[39]、ResNet[40]，要么将每个单个模态表示在自己的向量表达空间中，该空间满足某些约束条件，如线性相关性[41]。<li>多模态翻译。多模态翻译学习从一个模态中的源实例到另一个模态中的目标实例的翻译。基于实例的翻译模型通过字典[37]，[42]在不同的情态之间架起桥梁，而生成性翻译模型则建立了一个更灵活的模型，可以将一种情态转换为另一种情态[43]，[44]。<li>多模态对齐。多模态对齐旨在发现不同模态之间的对应关系。它既可以直接应用于视觉基础等多模态任务，也可以作为多模态预训练语言模型中的预训练任务<li>多模态融合。多模态融合指的是将来自不同模态的信息连接起来进行预测的过程[27]，其中应用了各种注意机制，如门控跨模态注意[46]、自底向上注意[47]等，以模拟跨模态模块中不同类型特征之间的交互。5）<li>多模式合作学习。多模式合作学习旨在通过调整其他模式的资源来缓解某一模式中资源不足的问题[27]。</ol><p>多模态预训练语言模型。基于一个包含文本图像对的大规模无监督多模态数据集，</p><p><strong>3 构建</strong></p><p>MMKG结构的本质是将传统KG中的符号知识（包括实体、概念和关系等）与其对应的图像相关联。完成这项任务有两种相反的方法：<strong>（1）用KG标记图像；</strong></p><p>CV社区开发了许多图像标记解决方案，可以利用这些解决方案在图像上标记知识符号（KG）。大多数图像标签解决方案学习从图像内容到各种标签集的映射，包括对象、场景、实体、属性、关系、事件和其他符号。学习过程由人工标注的数据集进行监督，该数据集要求群组工作人员绘制边界框，并用给定的标签标注图像或图像区域，如图2所示。一些著名的基于图像的视觉知识提取系统如表2a所示，可用于通过图像标记构建MMKG。根据要链接的符号类别，将图像链接到符号的过程可分为几个细分任务：视觉实体/概念提取（第3.1.1节）、视觉关系提取（第3.1.2节）和视觉事件提取（第3.1.3节）。</p><p><strong>（2）用KG标记图像。</strong></p><p>符号基础是指找到适当的多模态数据项（如图像）以表示传统知识中存在的符号知识的过程。与图像标注方式相比，符号联系方式在MMKG施工中的应用更为广泛。大多数现有MMKG都是以这种方式建造的，如表2b所示。</p><p>在本小节的其余部分中，我们将介绍在几个细分任务中将符号与图像联系起来的过程：实体联系（第3.2.1节）、概念联系（第3.2.2节）和关系联系（第3.2.3节）。</p><p>1.基于实体的</p><p>实体接地旨在将KG中的实体接地到相应的多模态数据，如图像、视频和音频[12]。现有的工作主要侧重于将实体与相应的图像联系起来。</p><p>挑战。将实体接地到图像的主要挑战如下：1）如何以低成本为实体找到足够多的高质量图像？2） 如何从大量噪声中选择与实体最匹配的图像？</p><p>进步。有两个主要来源可以找到实体的图像：（1）来自在线百科全书（如维基百科）和（2）通过网络搜索引擎从互联网。</p><p>2.基于概念的</p><p>概念基础旨在为视觉概念找到具有代表性的、有区别的和多样的图像。</p><p>挑战尽管一些视觉上统一的概念（如男人、女人、卡车和狗）也可3.以通过3.2.1中介绍的实体基础方法基础到图像，其他概念的符号基础面临着新的挑战：1）并不是所有的概念都能正确地可视化。例如，非宗教主义者不能基于某个特定的形象。如何区分可视概念和非可视概念？2） 如何从一组相关图像中找到一个可视化概念的代表性图像？请注意，可视化概念的图像可能非常多样。例如，说到公主，人们经常会想到几个不同的形象，比如迪士尼公主、历史电影中的古代公主或新闻中的现代公主。因此，我们必须考虑图像的多样性。</p><p>进步。为了应对上述挑战，相关研究分为三个任务：可视化概念判断、代表性图像选择和图像多样化。</p><p>3.基于关系的</p><p>关系基础是从图像数据语料库或互联网上找到可以代表特定关系的图像。输入可以是该关系的一个或多个三元组，输出应该是该关系最具代表性的图像。</p><p>挑战。当我们使用三元组作为查询来检索关系的图像时，排名靠前的图像通常与三元组的主语和宾语更相关，但与关系本身无关。如何找到能够反映输入三元组语义关系的图像？</p><p>进步。现有的关系基础研究主要集中在空间或动作关系上，如左的、上的、骑的和吃的。</p><p><strong>4 应用</strong></p><p>1.MMKG内的应用</p><p>n-MMKG应用指的是在MMKG范围内执行的任务，其中已经学习了实体、概念和关系的嵌入。因此，在介绍MMKG应用程序之前，我们先简要介绍一下MMKG中知识的分布式表示学习，也称为MMKG嵌入。</p><ol><li>连接预测<li>元组分类<li>实体分类<li>实体对齐</ol><p>2.MMKG外的应用</p><ol><li>多模态实体识别与连接<li>视觉问答<li>图文匹配<li>多模态生成任务<li>多模式推荐系统</ol><p><strong>6 结论</strong></p><p>我们是第一个全面调查由文本和图像构建的MMKG的现有工作的人。我们系统地回顾了MMKG施工和应用方面的现有工作。我们比较了主流MMKG的内容和构造方式。我们分析了MMKG结构和应用中不同解决方案的优缺点。我们不仅指出了MMKG建设和应用中现有任务的一些潜在机会，还列出了MMKG建设和应用的一些有希望的未来方向</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>Generating Explanations to Understand and Repair Embedding-based Entity Alignment
-Wei Hu
-Nanjing University
</pre></table></code></div></div><p>通过局部子图，解释实体对齐的结果</p><p>GFS: Graph-based Feature Synthesis for Prediction over Relational Databases</p><p>将表列生成向量，查找关系表，预测标签</p><p><img data-src="/HeBlog//assets/images/2021-12-13-论文阅读笔记-知识图谱/image-20240201171433998.png" alt="image-20240201171433998" data-proofer-ignore></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/HeBlog//categories/research/'>Research</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> 本文由作者按照 <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> 进行授权</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">分享</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=论文阅读笔记-知识图谱 - HeWang&amp;url=https://hewang234.github.io/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=论文阅读笔记-知识图谱 - HeWang&amp;u=https://hewang234.github.io/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https://hewang234.github.io/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/&amp;text=论文阅读笔记-知识图谱 - HeWang" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="分享链接" data-title-succeed="链接已复制！"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">最近更新</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E5%A4%9A%E6%A8%A1%E6%80%81/">论文阅读笔记-多模态</a><li><a href="/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a><li><a href="/HeBlog/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E9%87%91%E8%9E%8D/">论文阅读笔记-金融</a><li><a href="/HeBlog/posts/%E9%87%91%E8%9E%8D%E7%9F%A5%E8%AF%86/">金融知识</a><li><a href="/HeBlog/posts/%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8shell%E5%91%BD%E4%BB%A4/">系统常用shell命令</a></ul></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">文章内容</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>相关文章</h3><div class="card-deck mb-4"><div class="card"> <a href="/HeBlog/posts/%E8%B7%9F%E6%9D%8E%E6%B2%90%E5%A4%A7%E4%BD%AC%E8%AF%BB%E8%AE%BA%E6%96%87/"><div class="card-body"> <em class="timeago small" data-ts="1639958400" > 2021-12-20 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>跟李沐大佬读论文</h3><div class="text-muted small"><p> 跟李沐大佬读论文 方法论 pass 1：标题、摘要、结论、图表、实验 pass 2：通读、总体流程、文献 pass 3：详细、实现 Transformer Attention is all you need 李沐大佬的讲解 位置嵌入：引入位置信息，直接与词嵌入相加 注意力机制：给和自身相似的分配更高的权重。QKV是同样的向量复制三份 多头：学习到多种在不同空间的特征 残...</p></div></div></a></div><div class="card"> <a href="/HeBlog/posts/ReID/"><div class="card-body"> <em class="timeago small" data-ts="1651881600" > 2022-05-07 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ReID</h3><div class="text-muted small"><p> ReID 1 PyRetri: PyTorch-based Library for Unsupervised Image Retrieval by Deep Convolutional Neural Networks https://github.com/PyRetri/PyRetri https://mp.weixin.qq.com/s/_NDw7pFmDB07mliHTA6VYQ...</p></div></div></a></div><div class="card"> <a href="/HeBlog/posts/WolframAlpha/"><div class="card-body"> <em class="timeago small" data-ts="1655510400" > 2022-06-18 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>WolframAlpha</h3><div class="text-muted small"><p> WolframAlpha 官网 https://www.wolframalpha.com/ ref： https://www.163.com/dy/article/FGUNDTRC054535JN.html https://reference.wolfram.com/language/guide/MatrixOperations.html https://reference.wo...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/HeBlog//posts/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="btn btn-outline-primary" prompt="上一篇"><p>实用机器学习笔记</p></a> <a href="/HeBlog//posts/%E8%B7%9F%E6%9D%8E%E6%B2%90%E5%A4%A7%E4%BD%AC%E8%AF%BB%E8%AE%BA%E6%96%87/" class="btn btn-outline-primary" prompt="下一篇"><p>跟李沐大佬读论文</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://twitter.com/sralanlee">HeWang</a>. <span data-toggle="tooltip" data-placement="top" title="除非另有说明，本网站上的博客文章均由作者按照知识共享署名 4.0 国际 (CC BY 4.0) 许可协议进行授权。">保留部分权利。</span></p></div><div class="footer-right"><p class="mb-0"> 本站由 <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> 生成，采用 <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> 主题。</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/HeBlog/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">搜索结果为空</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/zh.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/HeBlog/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/HeBlog/app.js"></script>
