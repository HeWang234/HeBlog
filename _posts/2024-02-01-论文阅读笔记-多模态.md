---
title: 论文阅读笔记-多模态
categories: [RESEARCH]
---

```
MUST: An Effective and Scalable Framework for Multimodal Search of Target Modality
-Yunjun Gao
-Zhejiang University
```

将图实体转换为向量，构建图索引，搜索

These baselines either merge the results of separate vector searches for each modality or perform a single-channel vector search by fusing all modalities.

Our framework employs a hybrid fusion mechanism, combining different modalities at multiple stages. Notably, we leverage vector weight learning to determine the importance of each modality, thereby enhancing the accuracy of joint similarity measurement. Additionally, the proposed framework utilizes a fused proximity graph index, enabling efficient joint search for multimodal queries. MUST offers several other advantageous properties, including pluggable design to integrate any advanced embedding techniques, user flexibility to customize weight preferences, and modularized index construction.

我们的框架采用了混合融合机制，在多个阶段结合了不同的模式。值得注意的是，我们利用向量权重学习来确定每个模态的重要性，从而提高了联合相似性度量的准确性。此外，提出的框架利用融合接近图索引，使联合搜索多模态查询成为可能。MUST提供了其他几个有利的特性，包括可插入的设计，以集成任何先进的嵌入技术，用户定制权重偏好的灵活性，以及模块化的索引构造。

![image-20240201171622543](./assets/images/2024-02-01-论文阅读笔记-多模态/image-20240201171622543.png)